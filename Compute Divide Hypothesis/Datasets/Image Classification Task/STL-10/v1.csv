model,paper-link,accuracy,title,github href,paper href,year
Wide-ResNet-101,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1,98.66,SpinalNet: Deep Neural Network with Gradual Input,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1/review/?hl=19850,2020
CN,https://paperswithcode.com/paper/toward-understanding-supervised,98.45,Toward Understanding Supervised Representation Learning with RKHS and GAN,,https://paperswithcode.com/paper/toward-understanding-supervised#results,2021
CN,https://paperswithcode.com/paper/toward-understanding-supervised,98.36,Toward Understanding Supervised Representation Learning with RKHS and GAN,,https://paperswithcode.com/paper/toward-understanding-supervised#results,2021
NSRL+CN,https://paperswithcode.com/paper/toward-understanding-supervised,98.36,Toward Understanding Supervised Representation Learning with RKHS and GAN,,https://paperswithcode.com/paper/toward-understanding-supervised#results,2021
NSRL+CN,https://paperswithcode.com/paper/toward-understanding-supervised,98.34,Toward Understanding Supervised Representation Learning with RKHS and GAN,,https://paperswithcode.com/paper/toward-understanding-supervised#results,2021
NSRL+CN,https://paperswithcode.com/paper/toward-understanding-supervised,98.24,Toward Understanding Supervised Representation Learning with RKHS and GAN,,https://paperswithcode.com/paper/toward-understanding-supervised#results,2021
CN,https://paperswithcode.com/paper/toward-understanding-supervised,98.17,Toward Understanding Supervised Representation Learning with RKHS and GAN,,https://paperswithcode.com/paper/toward-understanding-supervised#results,2021
NAT-M4,https://paperswithcode.com/paper/neural-architecture-transfer,97.9,Neural Architecture Transfer,https://paperswithcode.com/paper/neural-architecture-transfer#code,https://paperswithcode.com/paper/neural-architecture-transfer/review/?hl=16591,2020
NAT-M3,https://paperswithcode.com/paper/neural-architecture-transfer,97.8,Neural Architecture Transfer,https://paperswithcode.com/paper/neural-architecture-transfer#code,https://paperswithcode.com/paper/neural-architecture-transfer/review/?hl=16592,2020
NAT-M2,https://paperswithcode.com/paper/neural-architecture-transfer,97.2,Neural Architecture Transfer,https://paperswithcode.com/paper/neural-architecture-transfer#code,https://paperswithcode.com/paper/neural-architecture-transfer/review/?hl=16593,2020
iGPT-L,https://paperswithcode.com/paper/generative-pretraining-from-pixels,97.1,Generative Pretraining from Pixels,https://paperswithcode.com/paper/generative-pretraining-from-pixels#code,https://paperswithcode.com/paper/generative-pretraining-from-pixels#results,2020
NAT-M1,https://paperswithcode.com/paper/neural-architecture-transfer,96.7,Neural Architecture Transfer,https://paperswithcode.com/paper/neural-architecture-transfer#code,https://paperswithcode.com/paper/neural-architecture-transfer/review/?hl=16594,2020
EnAET,https://paperswithcode.com/paper/enaet-self-trained-ensemble-autoencoding,95.48,EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations,https://paperswithcode.com/paper/enaet-self-trained-ensemble-autoencoding#code,https://paperswithcode.com/paper/enaet-self-trained-ensemble-autoencoding/review/?hl=8860,2019
VGG-19bn,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1,95.44,SpinalNet: Deep Neural Network with Gradual Input,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1/review/?hl=19871,2020
FixMatch,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,94.83,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
ReMixMatch,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,94.77,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
AMDIM,https://paperswithcode.com/paper/190600910,94.5,Learning Representations by Maximizing Mutual Information Across Views,https://paperswithcode.com/paper/190600910#code,https://paperswithcode.com/paper/190600910#results,2019
MixMatch,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi,94.41,MixMatch: A Holistic Approach to Semi-Supervised Learning,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi#code,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi/review/?hl=6157,2019
AMDIM-L,https://paperswithcode.com/paper/generative-pretraining-from-pixels,94.2,Generative Pretraining from Pixels,https://paperswithcode.com/paper/generative-pretraining-from-pixels#code,https://paperswithcode.com/paper/generative-pretraining-from-pixels#results,2020
ReMixMatch,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1,93.82,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1#code,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1/review/?hl=20216,2019
AMDIM,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised,93.80,A Framework For Contrastive Self-Supervised Learning And Designing A New Approach,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised#code,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised/review/?hl=19920,2020
ReMixMatch,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1,93.23,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1#code,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1/review/?hl=20215,2019
MP*,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural,93.19,Increasing Trustworthiness of Deep Neural Networks via Accuracy Monitoring,,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural/review/?hl=19903,2020
UDA,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,92.34,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
YADIM,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised,92.15,A Framework For Contrastive Self-Supervised Learning And Designing A New Approach,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised#code,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised/review/?hl=19921,2020
FixMatch,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,92.02,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
NSGANetV2,https://paperswithcode.com/paper/nsganetv2-evolutionary-multi-objective,92.0,NSGANetV2: Evolutionary Multi-Objective Surrogate-Assisted Neural Architecture Search,https://paperswithcode.com/paper/nsganetv2-evolutionary-multi-objective#code,https://paperswithcode.com/paper/nsganetv2-evolutionary-multi-objective/review/?hl=19908,2020
SESN,https://paperswithcode.com/paper/scale-equivariant-steerable-networks-1,91.49,Scale-Equivariant Steerable Networks,,https://paperswithcode.com/paper/scale-equivariant-steerable-networks-1/review/?hl=19315,2019
Harmonic WRN-16-8,https://paperswithcode.com/paper/harmonic-networks-with-limited-training,90.45,Harmonic Networks with Limited Training Samples,https://paperswithcode.com/paper/harmonic-networks-with-limited-training#code,https://paperswithcode.com/paper/harmonic-networks-with-limited-training/review/?hl=6163,2019
wrn16/8 D8 D4 D1,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1,90.20,General -Equivariant Steerable CNNs,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#code,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#results,2019
MixMatch,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1,89.82,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1#code,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1/review/?hl=20214,2019
MixMatch,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,89.59,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
wrn16/8* D8 D4 D1,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1,89.43,General -Equivariant Steerable CNNs,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#code,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#results,2019
wrn16/8* D1 D1 D1,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1,88.95,General -Equivariant Steerable CNNs,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#code,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#results,2019
wrn16/8 D1 D1 D1,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1,88.83,General -Equivariant Steerable CNNs,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#code,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#results,2019
IIC,https://paperswithcode.com/paper/invariant-information-distillation-for,88.8,Invariant Information Clustering for Unsupervised Image Classification and Segmentation,https://paperswithcode.com/paper/invariant-information-distillation-for#code,https://paperswithcode.com/paper/invariant-information-distillation-for/review/?hl=4372,2018
IIC,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi,88.80,MixMatch: A Holistic Approach to Semi-Supervised Learning,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi#code,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi/review/?hl=20187,2019
SOPCNN,https://paperswithcode.com/paper/stochastic-optimization-of-plain,88.08,Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods,,https://paperswithcode.com/paper/stochastic-optimization-of-plain#results,2020
TS,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural,88.03,Increasing Trustworthiness of Deep Neural Networks via Accuracy Monitoring,,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural/review/?hl=19902,2020
CutOut,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi,87.36,MixMatch: A Holistic Approach to Semi-Supervised Learning,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi#code,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi/review/?hl=20186,2019
Cutout,https://paperswithcode.com/paper/improved-regularization-of-convolutional,87.26,Improved Regularization of Convolutional Neural Networks with Cutout,https://paperswithcode.com/paper/improved-regularization-of-convolutional#code,https://paperswithcode.com/paper/improved-regularization-of-convolutional/review/?hl=4409,2017
wrn16/8,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1,87.26,General -Equivariant Steerable CNNs,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#code,https://paperswithcode.com/paper/general-e2-equivariant-steerable-cnns-1#results,2019
Hamiltonian,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep,85.5,Reversible Architectures for Arbitrarily Deep Residual Neural Networks,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep#code,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep/review/?hl=660,2017
ResNet-18+MM+FRL,https://paperswithcode.com/paper/towards-class-specific-unit,85.42,Learning Class Unique Features in Fine-Grained Visual Classification,,https://paperswithcode.com/paper/towards-class-specific-unit/review/?hl=37894,2020
MidPoint,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep,84.6,Reversible Architectures for Arbitrarily Deep Residual Neural Networks,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep#code,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep/review/?hl=20205,2017
cosine function,https://paperswithcode.com/paper/image-augmentation-for-object-image,84.38,Image Augmentation for Object Image Classification Based On Combination of PreTrained CNN and SVM,,https://paperswithcode.com/paper/image-augmentation-for-object-image#results,2018
HybridNet,https://paperswithcode.com/paper/hybridnet-classification-and-reconstruction,84.10,HybridNet: Classification and Reconstruction Cooperation for Semi-Supervised Learning,,https://paperswithcode.com/paper/hybridnet-classification-and-reconstruction/review/?hl=20203,2018
Leapfrog,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep,83.7,Reversible Architectures for Arbitrarily Deep Residual Neural Networks,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep#code,https://paperswithcode.com/paper/reversible-architectures-for-arbitrarily-deep/review/?hl=20206,2017
skewing,https://paperswithcode.com/paper/image-augmentation-for-object-image,83.47,Image Augmentation for Object Image Classification Based On Combination of PreTrained CNN and SVM,,https://paperswithcode.com/paper/image-augmentation-for-object-image#results,2018
elastic distortion,https://paperswithcode.com/paper/image-augmentation-for-object-image,83.45,Image Augmentation for Object Image Classification Based On Combination of PreTrained CNN and SVM,,https://paperswithcode.com/paper/image-augmentation-for-object-image#results,2018
PSLR-knn,https://paperswithcode.com/paper/probabilistic-structural-latent,83.2,Probabilistic Structural Latent Representation for Unsupervised Embedding,,https://paperswithcode.com/paper/probabilistic-structural-latent#results,2020
elastic distortion,https://paperswithcode.com/paper/image-augmentation-for-object-image,83.00,Image Augmentation for Object Image Classification Based On Combination of PreTrained CNN and SVM,,https://paperswithcode.com/paper/image-augmentation-for-object-image#results,2018
ResNet baseline,https://paperswithcode.com/paper/hybridnet-classification-and-reconstruction,82.00,HybridNet: Classification and Reconstruction Cooperation for Semi-Supervised Learning,,https://paperswithcode.com/paper/hybridnet-classification-and-reconstruction/review/?hl=20204,2018
Greedy InfoMax,https://paperswithcode.com/paper/greedy-infomax-for-biologically-plausible,81.9,Putting An End to End-to-End: Gradient-Isolated Learning of Representations,https://paperswithcode.com/paper/greedy-infomax-for-biologically-plausible#code,https://paperswithcode.com/paper/greedy-infomax-for-biologically-plausible/review/?hl=27713,2019
rotation,https://paperswithcode.com/paper/image-augmentation-for-object-image,81.45,Image Augmentation for Object Image Classification Based On Combination of PreTrained CNN and SVM,,https://paperswithcode.com/paper/image-augmentation-for-object-image#results,2018
ResNet18,https://paperswithcode.com/paper/extended-batch-normalization,81.04,Extended Batch Normalization,,https://paperswithcode.com/paper/extended-batch-normalization/review/?hl=19896,2020
VGG8B + LocalLearning + CO,https://paperswithcode.com/paper/training-neural-networks-with-local-error,80.75,Training Neural Networks with Local Error Signals,https://paperswithcode.com/paper/training-neural-networks-with-local-error#code,https://paperswithcode.com/paper/training-neural-networks-with-local-error/review/?hl=11260,2019
ResNet18,https://paperswithcode.com/paper/extended-batch-normalization,79.3,Extended Batch Normalization,,https://paperswithcode.com/paper/extended-batch-normalization/review/?hl=19897,2020
PSLR-Linear,https://paperswithcode.com/paper/probabilistic-structural-latent,78.8,Probabilistic Structural Latent Representation for Unsupervised Embedding,,https://paperswithcode.com/paper/probabilistic-structural-latent#results,2020
ResNet18,https://paperswithcode.com/paper/extended-batch-normalization,78.65,Extended Batch Normalization,,https://paperswithcode.com/paper/extended-batch-normalization/review/?hl=19893,2020
Mean Teacher,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,78.57,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
CPC†,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised,78.36,A Framework For Contrastive Self-Supervised Learning And Designing A New Approach,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised#code,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised/review/?hl=19922,2020
Hamiltonian,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial,78.3,Deep Neural Networks Motivated by Partial Differential Equations,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial#code,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial/review/?hl=20223,2018
CC-GAN²,https://paperswithcode.com/paper/semi-supervised-learning-with-context,77.8,Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks,https://paperswithcode.com/paper/semi-supervised-learning-with-context#code,https://paperswithcode.com/paper/semi-supervised-learning-with-context/review/?hl=676,2016
CC-GAN,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1,77.80,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1#code,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1/review/?hl=20213,2019
Parabolic,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial,77.0,Deep Neural Networks Motivated by Partial Differential Equations,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial#code,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial/review/?hl=20222,2018
Scat + WRN 20-8,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid,76.6,Scaling the Scattering Transform: Deep Hybrid Networks,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid#code,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid/review/?hl=19872,2017
ResNet18,https://paperswithcode.com/paper/extended-batch-normalization,76.49,Extended Batch Normalization,,https://paperswithcode.com/paper/extended-batch-normalization/review/?hl=19898,2020
Exemplar CNN,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid,75.7,Scaling the Scattering Transform: Deep Hybrid Networks,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid#code,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid/review/?hl=19884,2017
ResNet18,https://paperswithcode.com/paper/extended-batch-normalization,75.57,Extended Batch Normalization,,https://paperswithcode.com/paper/extended-batch-normalization/review/?hl=19894,2020
Stacked what-where AE,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid,74.33,Scaling the Scattering Transform: Deep Hybrid Networks,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid#code,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid/review/?hl=19885,2017
SWWAE,https://paperswithcode.com/paper/hybridnet-classification-and-reconstruction,74.33,HybridNet: Classification and Reconstruction Cooperation for Semi-Supervised Learning,,https://paperswithcode.com/paper/hybridnet-classification-and-reconstruction/review/?hl=20202,2018
SWWAE,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1,74.30,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1#code,https://paperswithcode.com/paper/remixmatch-semi-supervised-learning-with-1/review/?hl=673,2019
SWWAE,https://paperswithcode.com/paper/stacked-what-where-auto-encoders,74.3,Stacked What-Where Auto-encoders,https://paperswithcode.com/paper/stacked-what-where-auto-encoders#code,https://paperswithcode.com/paper/stacked-what-where-auto-encoders/review/?hl=674,2015
Second-order,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial,74.3,Deep Neural Networks Motivated by Partial Differential Equations,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial#code,https://paperswithcode.com/paper/deep-neural-networks-motivated-by-partial/review/?hl=20224,2018
Convolutional Clustering,https://paperswithcode.com/paper/convolutional-clustering-for-unsupervised,74.1,Convolutional Clustering for Unsupervised Learning,,https://paperswithcode.com/paper/convolutional-clustering-for-unsupervised/review/?hl=675,2015
?-Model,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,73.77,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,https://paperswithcode.com/paper/discriminative-unsupervised-feature-learning-1,72.8,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,,https://paperswithcode.com/paper/discriminative-unsupervised-feature-learning-1#results,2014
ResNet18,https://paperswithcode.com/paper/extended-batch-normalization,72.66,Extended Batch Normalization,,https://paperswithcode.com/paper/extended-batch-normalization/review/?hl=19895,2020
Pseudo-Labeling,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1,72.01,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#code,https://paperswithcode.com/paper/fixmatch-simplifying-semi-supervised-learning-1#results,2020
Entropy,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural,71.65,Increasing Trustworthiness of Deep Neural Networks via Accuracy Monitoring,,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural/review/?hl=19901,2020
BDW,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised,71.12,"Don’t Wait, Just Weight: Improving Unsupervised Representations by Learning Goal-Driven Instance Weights",,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised#results,2020
MP,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural,71.05,Increasing Trustworthiness of Deep Neural Networks via Accuracy Monitoring,,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural/review/?hl=19900,2020
CNN,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid,70.7,Scaling the Scattering Transform: Deep Hybrid Networks,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid#code,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid/review/?hl=19881,2017
An Analysis of Unsupervised Pre-training in Light of Recent Advances,https://paperswithcode.com/paper/an-analysis-of-unsupervised-pre-training-in,70.2,An Analysis of Unsupervised Pre-training in Light of Recent Advances,https://paperswithcode.com/paper/an-analysis-of-unsupervised-pre-training-in#code,https://paperswithcode.com/paper/an-analysis-of-unsupervised-pre-training-in/review/?hl=671,2014
Multi-Task Bayesian Optimization,https://paperswithcode.com/paper/multi-task-bayesian-optimization,70.1,Multi-Task Bayesian Optimization,https://paperswithcode.com/paper/multi-task-bayesian-optimization#code,https://paperswithcode.com/paper/multi-task-bayesian-optimization#results,2013
NN-Weighter,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised,69.15,"Don’t Wait, Just Weight: Improving Unsupervised Representations by Learning Goal-Driven Instance Weights",,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised#results,2020
Accuracy Monitoring,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural,68.62,Increasing Trustworthiness of Deep Neural Networks via Accuracy Monitoring,,https://paperswithcode.com/paper/increasing-trustworthiness-of-deep-neural/review/?hl=19899,2020
C-SVDDNet,https://paperswithcode.com/paper/unsupervised-feature-learning-with-c-svddnet,68.2,Unsupervised Feature Learning with C-SVDDNet,,https://paperswithcode.com/paper/unsupervised-feature-learning-with-c-svddnet/review/?hl=672,2014
RotNet,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised,68.19,"Don’t Wait, Just Weight: Improving Unsupervised Representations by Learning Goal-Driven Instance Weights",,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised#results,2020
DFF Committees,https://paperswithcode.com/paper/committees-of-deep-feedforward-networks,68,Committees of deep feedforward networks trained with few data,,https://paperswithcode.com/paper/committees-of-deep-feedforward-networks/review/?hl=668,2014
Hierarchical Matching Pursuit,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid,64.6,Scaling the Scattering Transform: Deep Hybrid Networks,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid#code,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid/review/?hl=19886,2017
L2RW,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised,63.13,"Don’t Wait, Just Weight: Improving Unsupervised Representations by Learning Goal-Driven Instance Weights",,https://paperswithcode.com/paper/dont-wait-just-weight-improving-unsupervised#results,2020
Discriminative Learning of Sum-Product Networks,https://paperswithcode.com/paper/discriminative-learning-of-sum-product,62.3,Discriminative Learning of Sum-Product Networks,,https://paperswithcode.com/paper/discriminative-learning-of-sum-product#results,2011
CKN,https://paperswithcode.com/paper/convolutional-kernel-networks,62.3,Convolutional Kernel Networks,,https://paperswithcode.com/paper/convolutional-kernel-networks/review/?hl=669,2014
S-CNN,https://paperswithcode.com/paper/selective-unsupervised-feature-learning-with,61.94,Selective Unsupervised Feature Learning with Convolutional Neural Network (S-CNN),,https://paperswithcode.com/paper/selective-unsupervised-feature-learning-with#results,2016
Simulated Fixations,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised,61,A Framework For Contrastive Self-Supervised Learning And Designing A New Approach,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised#code,https://paperswithcode.com/paper/a-framework-for-contrastive-self-supervised/review/?hl=661,2020
No more meta-parameter tuning in unsupervised sparse feature learning,https://paperswithcode.com/paper/no-more-meta-parameter-tuning-in-unsupervised,61,No more meta-parameter tuning in unsupervised sparse feature learning,,https://paperswithcode.com/paper/no-more-meta-parameter-tuning-in-unsupervised/review/?hl=666,2014
Convolutional K-means Network,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid,60.2,Scaling the Scattering Transform: Deep Hybrid Networks,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid#code,https://paperswithcode.com/paper/scaling-the-scattering-transform-deep-hybrid/review/?hl=19887,2017
Receptive Fields,https://paperswithcode.com/paper/receptive-fields-without-spike-triggering,60.1,Receptive Fields without Spike-Triggering,,https://paperswithcode.com/paper/receptive-fields-without-spike-triggering#results,2007
PWD,https://paperswithcode.com/paper/effective-version-space-reduction-for,59.45,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19913,2020
GVD,https://paperswithcode.com/paper/effective-version-space-reduction-for,59.33,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19914,2020
VR,https://paperswithcode.com/paper/effective-version-space-reduction-for,59.13,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=664,2020
Core SET,https://paperswithcode.com/paper/effective-version-space-reduction-for,58.93,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19911,2020
GE,https://paperswithcode.com/paper/effective-version-space-reduction-for,58.84,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19909,2020
DFAL,https://paperswithcode.com/paper/effective-version-space-reduction-for,58.81,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19912,2020
Random,https://paperswithcode.com/paper/effective-version-space-reduction-for,58.15,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=659,2020
BALD-MCD,https://paperswithcode.com/paper/effective-version-space-reduction-for,57.35,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19910,2020
Sign-symmetry,https://paperswithcode.com/paper/how-important-is-weight-symmetry-in,57.32,How Important is Weight Symmetry in Backpropagation?,https://paperswithcode.com/paper/how-important-is-weight-symmetry-in#code,https://paperswithcode.com/paper/how-important-is-weight-symmetry-in/review/?hl=20692,2015
M2-PWD,https://paperswithcode.com/paper/effective-version-space-reduction-for,57.31,Effective Version Space Reduction for Convolutional Neural Networks,,https://paperswithcode.com/paper/effective-version-space-reduction-for/review/?hl=19915,2020
soft ica,https://paperswithcode.com/paper/ica-with-reconstruction-cost-for-efficient,51.5,ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning,,https://paperswithcode.com/paper/ica-with-reconstruction-cost-for-efficient#results,2011
