model,paper-link,error,title,github href,paper href,year,accuracy
WRN28-10,https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1,0.99,Sharpness-Aware Minimization for Efficiently Improving Generalization,https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1#code,https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1/review/?hl=21319,2020,99.01
E2E-M3,https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and,1.0,Rethinking Recurrent Neural Networks and Other Improvements for Image Classification,https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and#code,https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and/review/?hl=36537,2020,99
Wide-ResNet-28-10,https://paperswithcode.com/paper/fast-autoaugment,1.1,Fast AutoAugment,https://paperswithcode.com/paper/fast-autoaugment#code,https://paperswithcode.com/paper/fast-autoaugment/review/?hl=9309,2019,98.9
Colornet,https://paperswithcode.com/paper/colornet-investigating-the-importance-of,1.11,ColorNet: Investigating the importance of color spaces for image classification,https://paperswithcode.com/paper/colornet-investigating-the-importance-of#code,https://paperswithcode.com/paper/colornet-investigating-the-importance-of/review/?hl=21468,2019,98.89
PBA [ho2019pba],https://paperswithcode.com/paper/190505393,1.2,Population Based Augmentation: Efficient Learning of Augmentation Policy Schedules,https://paperswithcode.com/paper/190505393#code,https://paperswithcode.com/paper/190505393/review/?hl=11242,2019,98.8
Cutout,https://paperswithcode.com/paper/improved-regularization-of-convolutional,1.30,Improved Regularization of Convolutional Neural Networks with Cutout,https://paperswithcode.com/paper/improved-regularization-of-convolutional#code,https://paperswithcode.com/paper/improved-regularization-of-convolutional/review/?hl=5392,2017,98.7
PyramidNet + AA,https://paperswithcode.com/paper/regularizing-neural-networks-via-adversarial,1.35,Regularizing Neural Networks via Adversarial Model Perturbation,https://paperswithcode.com/paper/regularizing-neural-networks-via-adversarial#code,https://paperswithcode.com/paper/regularizing-neural-networks-via-adversarial#results,2020,98.65
WRN + fixup init + mixup + cutout,https://paperswithcode.com/paper/fixup-initialization-residual-learning,1.4,Fixup Initialization: Residual Learning Without Normalization,https://paperswithcode.com/paper/fixup-initialization-residual-learning#code,https://paperswithcode.com/paper/fixup-initialization-residual-learning/review/?hl=3947,2019,98.6
Drop-Activation,https://paperswithcode.com/paper/drop-activation-implicit-parameter-reduction,1.46,Drop-Activation: Implicit Parameter Reduction and Harmonic Regularization,https://paperswithcode.com/paper/drop-activation-implicit-parameter-reduction#code,https://paperswithcode.com/paper/drop-activation-implicit-parameter-reduction/review/?hl=5393,2018,98.54
SOPCNN,https://paperswithcode.com/paper/stochastic-optimization-of-plain,1.50,Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods,,https://paperswithcode.com/paper/stochastic-optimization-of-plain#results,2020,98.5
EraseReLU,https://paperswithcode.com/paper/eraserelu-a-simple-way-to-ease-the-training,1.54,EraseReLU: A Simple Way to Ease the Training of Deep Convolution Neural Networks,,https://paperswithcode.com/paper/eraserelu-a-simple-way-to-ease-the-training/review/?hl=3085,2017,98.46
Wide Residual Networks,https://paperswithcode.com/paper/wide-residual-networks,1.54,Wide Residual Networks,https://paperswithcode.com/paper/wide-residual-networks#code,https://paperswithcode.com/paper/wide-residual-networks/review/?hl=5394,2016,98.46
CoPaNet-R-164,https://paperswithcode.com/paper/deep-competitive-pathway-networks,1.58,Deep Competitive Pathway Networks,https://paperswithcode.com/paper/deep-competitive-pathway-networks#code,https://paperswithcode.com/paper/deep-competitive-pathway-networks/review/?hl=2478,2017,98.42
DenseNet,https://paperswithcode.com/paper/densely-connected-convolutional-networks,1.59,Densely Connected Convolutional Networks,https://paperswithcode.com/paper/densely-connected-convolutional-networks#code,https://paperswithcode.com/paper/densely-connected-convolutional-networks/review/?hl=2447,2016,98.41
Multilevel Residual Networks,https://paperswithcode.com/paper/residual-networks-of-residual-networks,1.59,Residual Networks of Residual Networks: Multilevel Residual Networks,https://paperswithcode.com/paper/residual-networks-of-residual-networks#code,https://paperswithcode.com/paper/residual-networks-of-residual-networks/review/?hl=5395,2016,98.41
VGG8B + LocalLearning + CO,https://paperswithcode.com/paper/training-neural-networks-with-local-error,1.65,Training Neural Networks with Local Error Signals,https://paperswithcode.com/paper/training-neural-networks-with-local-error#code,https://paperswithcode.com/paper/training-neural-networks-with-local-error/review/?hl=11243,2019,98.35
Tree+Max-Avg pooling,https://paperswithcode.com/paper/generalizing-pooling-functions-in,1.7,"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",https://paperswithcode.com/paper/generalizing-pooling-functions-in#code,https://paperswithcode.com/paper/generalizing-pooling-functions-in/review/?hl=603,2015,98.3
Wide ResNet,https://paperswithcode.com/paper/wide-residual-networks,1.7,Wide Residual Networks,https://paperswithcode.com/paper/wide-residual-networks#code,https://paperswithcode.com/paper/wide-residual-networks/review/?hl=2061,2016,98.3
Stochastic Depth,https://paperswithcode.com/paper/deep-networks-with-stochastic-depth,1.75,Deep Networks with Stochastic Depth,https://paperswithcode.com/paper/deep-networks-with-stochastic-depth#code,https://paperswithcode.com/paper/deep-networks-with-stochastic-depth/review/?hl=2484,2016,98.25
RCNN-96,,1.8,,,,,98.2
BNM NiN,https://paperswithcode.com/paper/batch-normalized-maxout-network-in-network,1.8,Batch-normalized Maxout Network in Network,https://paperswithcode.com/paper/batch-normalized-maxout-network-in-network#code,https://paperswithcode.com/paper/batch-normalized-maxout-network-in-network/review/?hl=604,2015,98.2
CMsC,https://paperswithcode.com/paper/competitive-multi-scale-convolution,1.8,Competitive Multi-scale Convolution,,https://paperswithcode.com/paper/competitive-multi-scale-convolution/review/?hl=605,2015,98.2
Regularization of Neural Networks using DropConnect,,1.9,,,,,98.1
DSN,https://paperswithcode.com/paper/deeply-supervised-nets,1.9,Deeply-Supervised Nets,https://paperswithcode.com/paper/deeply-supervised-nets#code,https://paperswithcode.com/paper/deeply-supervised-nets/review/?hl=597,2014,98.1
MLR DNN,,1.9,,,,,98.1
MIM,https://paperswithcode.com/paper/on-the-importance-of-normalisation-layers-in,2.0,On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units,,https://paperswithcode.com/paper/on-the-importance-of-normalisation-layers-in/review/?hl=602,2015,98
FractalNet,https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without,2.01,FractalNet: Ultra-Deep Neural Networks without Residuals,https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without#code,https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without/review/?hl=2448,2016,97.99
DCNN,https://paperswithcode.com/paper/multi-digit-number-recognition-from-street,2.2,Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks,https://paperswithcode.com/paper/multi-digit-number-recognition-from-street#code,https://paperswithcode.com/paper/multi-digit-number-recognition-from-street/review/?hl=596,2013,97.8
BinaryConnect,https://paperswithcode.com/paper/binaryconnect-training-deep-neural-networks,2.2,BinaryConnect: Training Deep Neural Networks with binary weights during propagations,https://paperswithcode.com/paper/binaryconnect-training-deep-neural-networks#code,https://paperswithcode.com/paper/binaryconnect-training-deep-neural-networks/review/?hl=606,2015,97.8
EnAET,https://paperswithcode.com/paper/enaet-self-trained-ensemble-autoencoding,2.22,EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations,https://paperswithcode.com/paper/enaet-self-trained-ensemble-autoencoding#code,https://paperswithcode.com/paper/enaet-self-trained-ensemble-autoencoding/review/?hl=8867,2019,97.78
PreActResNet18,https://paperswithcode.com/paper/regularizing-neural-networks-via-adversarial,2.30,Regularizing Neural Networks via Adversarial Model Perturbation,https://paperswithcode.com/paper/regularizing-neural-networks-via-adversarial#code,https://paperswithcode.com/paper/regularizing-neural-networks-via-adversarial#results,2020,97.7
Network in Network,https://paperswithcode.com/paper/network-in-network,2.35,Network In Network,https://paperswithcode.com/paper/network-in-network#code,https://paperswithcode.com/paper/network-in-network/review/?hl=2449,2013,97.65
ReNet,https://paperswithcode.com/paper/renet-a-recurrent-neural-network-based,2.4,ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks,https://paperswithcode.com/paper/renet-a-recurrent-neural-network-based#code,https://paperswithcode.com/paper/renet-a-recurrent-neural-network-based/review/?hl=600,2015,97.6
Maxout,https://paperswithcode.com/paper/maxout-networks,2.5,Maxout Networks,https://paperswithcode.com/paper/maxout-networks#code,https://paperswithcode.com/paper/maxout-networks/review/?hl=593,2013,97.5
MixMatch,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi,2.59,MixMatch: A Holistic Approach to Semi-Supervised Learning,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi#code,https://paperswithcode.com/paper/mixmatch-a-holistic-approach-to-semi/review/?hl=11244,2019,97.41
Stochastic Pooling,https://paperswithcode.com/paper/stochastic-pooling-for-regularization-of-deep,2.8,Stochastic Pooling for Regularization of Deep Convolutional Neural Networks,https://paperswithcode.com/paper/stochastic-pooling-for-regularization-of-deep#code,https://paperswithcode.com/paper/stochastic-pooling-for-regularization-of-deep/review/?hl=592,2013,97.2
Deep Complex,https://paperswithcode.com/paper/deep-complex-networks,3.3,Deep Complex Networks,https://paperswithcode.com/paper/deep-complex-networks#code,https://paperswithcode.com/paper/deep-complex-networks/review/?hl=607,2017,96.7
FLSCNN,https://paperswithcode.com/paper/enhanced-image-classification-with-a-fast,4.0,Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network,,https://paperswithcode.com/paper/enhanced-image-classification-with-a-fast/review/?hl=598,2015,96
Convolutional neural networks applied to house numbers digit classification,,4.9,,,,,95.1
CLS-GAN,https://paperswithcode.com/paper/loss-sensitive-generative-adversarial,5.98,Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities,https://paperswithcode.com/paper/loss-sensitive-generative-adversarial#code,https://paperswithcode.com/paper/loss-sensitive-generative-adversarial/review/?hl=2076,2017,94.02
Improved GAN,https://paperswithcode.com/paper/improved-techniques-for-training-gans,8.11,Improved Techniques for Training GANs,https://paperswithcode.com/paper/improved-techniques-for-training-gans#code,https://paperswithcode.com/paper/improved-techniques-for-training-gans/review/?hl=11245,2016,91.89
Sign-symmetry,https://paperswithcode.com/paper/how-important-is-weight-symmetry-in,10.16,How Important is Weight Symmetry in Backpropagation?,https://paperswithcode.com/paper/how-important-is-weight-symmetry-in#code,https://paperswithcode.com/paper/how-important-is-weight-symmetry-in/review/?hl=20691,2015,89.84
ANODE,https://paperswithcode.com/paper/augmented-neural-odes,16.5,Augmented Neural ODEs,https://paperswithcode.com/paper/augmented-neural-odes#code,https://paperswithcode.com/paper/augmented-neural-odes/review/?hl=9322,2019,83.5
Skip DGN,https://paperswithcode.com/paper/auxiliary-deep-generative-models,16.61,Auxiliary Deep Generative Models,https://paperswithcode.com/paper/auxiliary-deep-generative-models#code,https://paperswithcode.com/paper/auxiliary-deep-generative-models/review/?hl=11246,2016,83.39
DCGAN,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1,22.48,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1#code,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1/review/?hl=11247,2015,77.52
Auxiliary DGN,https://paperswithcode.com/paper/auxiliary-deep-generative-models,22.86,Auxiliary Deep Generative Models,https://paperswithcode.com/paper/auxiliary-deep-generative-models#code,https://paperswithcode.com/paper/auxiliary-deep-generative-models/review/?hl=11248,2016,77.14
Supervised CNN,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1,28.87,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1#code,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1/review/?hl=11249,2015,71.13
M1+M2,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1,36.02,Semi-Supervised Learning with Deep Generative Models,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1#code,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1/review/?hl=11250,2014,63.98
DGN,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1,36.02,Semi-Supervised Learning with Deep Generative Models,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1#code,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1/review/?hl=11251,2014,63.98
M1+TSVM,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1,54.33,Semi-Supervised Learning with Deep Generative Models,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1#code,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1/review/?hl=11252,2014,45.67
M1+KNN,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1,65.63,Semi-Supervised Learning with Deep Generative Models,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1#code,https://paperswithcode.com/paper/semi-supervised-learning-with-deep-generative-1/review/?hl=11253,2014,34.37
TSVM,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1,66.55,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1#code,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1/review/?hl=11254,2015,33.45
KNN,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1,77.93,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1#code,https://paperswithcode.com/paper/unsupervised-representation-learning-with-1/review/?hl=11255,2015,22.07
