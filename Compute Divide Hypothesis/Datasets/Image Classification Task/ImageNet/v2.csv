Ranking,Model,Paper Title,Accuracy,Parameters,Parameters (missing),Paper Link,Year,Tags,Industry Affiliation,Academia Affiliation
1,CoAtNet-7,CoAtNet: Marrying Convolution and Attention for All Data Sizes,90.88%,,2440M,https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention,2021,Conv+Transformer,Google Brain,
2,ViT-G/14,Scaling Vision Transformers,90.45%,,1843M,https://paperswithcode.com/paper/scaling-vision-transformers,2021,Transformer,Google Brain,
3,CoAtNet-6,CoAtNet: Marrying Convolution and Attention for All Data Sizes,90.45%,,1470M,https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention,2021,Conv+Transformer,Google Brain,
4,ViT-MoE-15B,Scaling Vision with Sparse Mixture of Experts,90.35%,,14700M,https://paperswithcode.com/paper/scaling-vision-with-sparse-mixture-of-experts,2021,Transformer,Google Brain,
5,Meta Pseudo Labels,Meta Pseudo Labels,90.20%,98.8,480M,https://paperswithcode.com/paper/meta-pseudo-labels,2021,EfficientNet,Google Brain,
6,SwinV2-G,Swin Transformer V2: Scaling Up Capacity and Resolution,90.17%,,,https://paperswithcode.com/paper/swin-transformer-v2-scaling-up-capacity-and,2021,,Microsoft Asia,
7,Florence-CoSwin-H,Florence: A New Foundation Model for Computer Vision,90.05%,99.02,,https://paperswithcode.com/paper/florence-a-new-foundation-model-for-computer,2021,,Microsoft,
8,Meta Pseudo Labels,Meta Pseudo Labels,90%,98.7,390M,https://paperswithcode.com/paper/meta-pseudo-labels,2021,EfficientNet,Google Brain,
9,NFNet-F4+,High-Performance Large-Scale Image Recognition Without Normalization,89.20%,,527M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,JFT-300M,DeepMind,
10,TokenLearner L/8,TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?,88.87%,,460M,https://paperswithcode.com/paper/tokenlearner-what-can-8-learned-tokens-do-for,2021,,Google ,Stony Brook University
11,ALIGN,Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision,88.64%,98.67%,480M,https://paperswithcode.com/paper/scaling-up-visual-and-vision-language,2021,EfficientNet,Google,
12,EfficientNet-L2-475,Sharpness-Aware Minimization for Efficiently Improving Generalization,88.61%,,480M,https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1,2020,EfficientNet,"Google, BlueShift",
13,BEiT-L,BEiT: BERT Pre-Training of Image Transformers,88.60%,98.66%,331M,https://paperswithcode.com/paper/beit-bert-pre-training-of-image-transformers,2021,Transformer,Microsoft Cloud AI,
14,FixEfficientNet-L2,Fixing the train-test resolution discrepancy: FixEfficientNet,88.50%,98.70%,480M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
15,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,88.40%,98.70%,480M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2020,EfficientNet,Google,Carnegie Mellon University
16,V-MoE-H/14,Scaling Vision with Sparse Mixture of Experts,88.36%,,7200M,https://paperswithcode.com/paper/scaling-vision-with-sparse-mixture-of-experts,2021,Transformer,Google Brain,
17,V-MoE-H/14,Scaling Vision with Sparse Mixture of Experts,88.23%,,2700M,https://paperswithcode.com/paper/scaling-vision-with-sparse-mixture-of-experts,2021,Transformer,Google Brain,
18,VIT-H/14,Scaling Vision with Sparse Mixture of Experts,88.08%,,656M,https://paperswithcode.com/paper/scaling-vision-with-sparse-mixture-of-experts,2021,Transformer,Google Brain,
19,Mixer-H/14,MLP-Mixer: An all-MLP Architecture for Vision,87.94%,,,https://paperswithcode.com/paper/mlp-mixer-an-all-mlp-architecture-for-vision,2021,MLP,Google Brain,
20,VIT-H448,Masked Autoencoders Are Scalable Vision Learners,87.8,,632M,https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision,2021,,Facebook AI Research,
21,ViT-L/16,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,87.76±0.03%,,307M,https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1,2020,Transformer,Google Brain,
22,CvT-W24,CvT: Introducing Convolutions to Vision Transformers,87.70%,,277M,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
23,BiT-L,Big Transfer (BiT): General Visual Representation Learning,87.54%,98.46%,,https://paperswithcode.com/paper/large-scale-learning-of-general-visual,2019,ResNet,Google Brain,
24,CSWin-L,CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows,87.5,,173M,https://paperswithcode.com/paper/cswin-transformer-a-general-vision,2021,Transformer,"Microsoft Asia, Microsoft Cloud AI",University of Science and Technology China
25,V-MoE-L/16,Scaling Vision with Sparse Mixture of Experts,87.41%,,3400M,https://paperswithcode.com/paper/scaling-vision-with-sparse-mixture-of-experts,2021,Transformer,Google Brain,
26,Swin-L,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,87.30%,,197M,https://paperswithcode.com/paper/swin-transformer-hierarchical-vision,2021,Transformer,Microsoft Asia,
27,FixEfficientNet-B7,Fixing the train-test resolution discrepancy: FixEfficientNet,87.10%,98.20%,66M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
28,VOLO-D5,VOLO: Vision Outlooker for Visual Recognition,87.10%,,296M,https://paperswithcode.com/paper/volo-vision-outlooker-for-visual-recognition,2021,,Sea AI Lab,National University of Singapore
29,16-TokenLearner B/16,TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?,87.07%,,,https://paperswithcode.com/paper/tokenlearner-what-can-8-learned-tokens-do-for,2021,JFT-300M,Google ,Stony Brook University
30,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,86.90%,98.10%,66M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
31,VIT-H,Masked Autoencoders Are Scalable Vision Learners,86.9,,,https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision,2021,,Facebook AI Research,
32,VOLO-D4,VOLO: Vision Outlooker for Visual Recognition,86.80%,,193M,https://paperswithcode.com/paper/volo-vision-outlooker-for-visual-recognition,2021,,Sea AI Lab,National University of Singapore
33,EfficientNetV2-L,EfficientNetV2: Smaller Models and Faster Training,86.80%,,121M,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster,2021,EfficientNet,Google Brain,
34,NFNet-F5 w/ SAM w/ augmult=16,Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error,86.78%,,377.2M,https://paperswithcode.com/paper/drawing-multiple-augmentation-samples-per,2021,,DeepMind,
35,FixEfficientNet-B6,Fixing the train-test resolution discrepancy: FixEfficientNet,86.70%,98.00%,43M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
36,NFNet-F6 w/ SAM,High-Performance Large-Scale Image Recognition Without Normalization,86.50%,97.90%,438.4M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
37,CaiT-M-48-448,Going deeper with Image Transformers,86.50%,,356M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
38,FixResNeXt-101 32x48d,Fixing the train-test resolution discrepancy,86.40%,98.00%,829M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy,2019,ResNeXt,Facebook AI Research,
39,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,86.40%,97.90%,43M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
40,FixEfficientNet-B5,Fixing the train-test resolution discrepancy: FixEfficientNet,86.40%,97.90%,30M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
41,LV-ViT-L,All Tokens Matter: Token Labeling for Training Better Vision Transformers,86.40%,,150M,https://paperswithcode.com/paper/token-labeling-training-a-85-5-top-1-accuracy,2021,Transformer,ByteDance,National University of Singapore
42,NFNet-F5 w/ SAM,High-Performance Large-Scale Image Recognition Without Normalization,86.30%,,377.2M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
43,CAIT-M36-448,Going deeper with Image Transformers,86.30%,,271M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
44,BEiT-B,BEiT: BERT Pre-Training of Image Transformers,86.30%,,86M,https://paperswithcode.com/paper/beit-bert-pre-training-of-image-transformers,2021,,Microsoft,
45,VOLO-D3,VOLO: Vision Outlooker for Visual Recognition,86.30%,,86M,https://paperswithcode.com/paper/volo-vision-outlooker-for-visual-recognition,2021,,Sea AI Lab,National University of Singapore
46,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,86.10%,97.80%,30M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
47,CAIT-M-36,Going deeper with Image Transformers,86.10%,,270.9M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
48,EfficientNetV2-M,EfficientNetV2: Smaller Models and Faster Training,86.10%,,55M,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster,2021,EfficientNet,Google Brain,
49,Refiner-ViT-L,Refiner: Refining Self-attention for Vision Transformers,86.03,,81M,https://paperswithcode.com/paper/refiner-refining-self-attention-for-vision,2021,Transformer,,National University of Singapore
50,NFNet-F5,High-Performance Large-Scale Image Recognition Without Normalization,86.00%,97.60%,,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
51,VOLO-D2,VOLO: Vision Outlooker for Visual Recognition,86%,,59M,https://paperswithcode.com/paper/volo-vision-outlooker-for-visual-recognition,2021,,Sea AI Lab,National University of Singapore
52,Swin-B,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,86%,,,https://paperswithcode.com/paper/swin-transformer-hierarchical-vision,2021,Transformer,Microsoft Asia,
53,XCiT-L24,XCiT: Cross-Covariance Image Transformers,86%,,,https://paperswithcode.com/paper/xcit-cross-covariance-image-transformers,2021,,Facebook AI Research,Sorbonne University
54,FixEfficientNet-B4,Fixing the train-test resolution discrepancy: FixEfficientNet,85.90%,97.70%,19M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
55,NFNet-F4,High-Performance Large-Scale Image Recognition Without Normalization,85.90%,,316.1M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
56,VIT-L,Masked Autoencoders Are Scalable Vision Learners,85.9,,,https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision,2021,,Facebook AI Research,
57,CAIT-M-24,Going deeper with Image Transformers,85.80%,,185.9M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
58,KDforAA,Circumventing Outliers of AutoAugment with Knowledge Distillation,85.80%,,88M,https://paperswithcode.com/paper/circumventing-outliers-of-autoaugment-with,2020,EfficientNet,Huawei Inc.,Tongji University
59,Fix-EfficientNet-B8,MaxUp: A Simple Way to Improve Generalization of Neural Network Training,85.80%,,87.42M,https://paperswithcode.com/paper/maxup-a-simple-way-to-improve-generalization,2020,EfficientNet,,UT Austin
60,XCiT-M24,XCiT: Cross-Covariance Image Transformers,85.80%,,,https://paperswithcode.com/paper/xcit-cross-covariance-image-transformers,2021,Transformer,Facebook AI Research,"Inria, Sorbonne University"
61,FixEfficientNet-B8,Fixing the train-test resolution discrepancy: FixEfficientNet,85.70%,97.60%,,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
62,NFNet-F3,High-Performance Large-Scale Image Recognition Without Normalization,85.70%,97.50%,254.9M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
63,EfficientNetV2-L,EfficientNetV2: Smaller Models and Faster Training,85.70%,,121M,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster,2021,EfficientNet,Google Brain,
64,XCiT-S24,XCiT: Cross-Covariance Image Transformers,85.60%,,,https://paperswithcode.com/paper/xcit-cross-covariance-image-transformers,2021,,Facebook AI Research,"Inria, Sorbonne University"
65,AdvProp,Adversarial Examples Improve Image Recognition,85.50%,97.30%,88M,https://paperswithcode.com/paper/adversarial-examples-improve-image,2019,EfficientNet,Google,Johns Hopkins University
66,HaloNet4,Scaling Local Self-Attention for Parameter Efficient Visual Backbones,85.50%,,87M,https://paperswithcode.com/paper/scaling-local-self-attention-for-parameter,2021,,Google,UC Berkeley
67,KDforAA,Circumventing Outliers of AutoAugment with Knowledge Distillation,85.50%,,66M,https://paperswithcode.com/paper/circumventing-outliers-of-autoaugment-with,2020,EfficientNet,Huawei Inc.,Tongji University
68,ResNeXt-101 32x48d,Exploring the Limits of Weakly Supervised Pretraining,85.40%,97.60%,829M,https://paperswithcode.com/paper/exploring-the-limits-of-weakly-supervised,2018,ResNeXt,Facebook ,
69,CAIT-S-36,Going deeper with Image Transformers,85.40%,,68.2M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
70,LV-ViT-M,All Tokens Matter: Token Labeling for Training Better Vision Transformers,85.40%,,56M,https://paperswithcode.com/paper/token-labeling-training-a-85-5-top-1-accuracy,2021,Transformer,ByteDance,"National University of Singapore, Nankai University"
71,EfficientNet-B8,RandAugment: Practical automated data augmentation with a reduced search space,85.40%,,,https://paperswithcode.com/paper/randaugment-practical-data-augmentation-with,2019,EfficientNet,Google Brain,
72,BiT-M,Big Transfer (BiT): General Visual Representation Learning,85.39%,97.69%,928M,https://paperswithcode.com/paper/large-scale-learning-of-general-visual,2019,ResNet,Google Brain,
73,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,85.30%,97.50%,19M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
74,CAIT-S-48,Going deeper with Image Transformers,85.30%,,89.5M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
75,ViT-L/16 Dosovitskiy et al.,MLP-Mixer: An all-MLP Architecture for Vision,85.30%,,,https://paperswithcode.com/paper/mlp-mixer-an-all-mlp-architecture-for-vision,2021,Transformer,Google Brain,
76,AdvProp,Adversarial Examples Improve Image Recognition,85.20%,97.20%,66M,https://paperswithcode.com/paper/adversarial-examples-improve-image,2019,EfficientNet,Google,Johns Hopkins University
77,DeiT-B 384,Training data-efficient image transformers & distillation through attention,85.20%,,87M,https://paperswithcode.com/paper/training-data-efficient-image-transformers,2020,Transformer,Facebook AI Research,Sorbonne University
78,VOLO-D1,VOLO: Vision Outlooker for Visual Recognition,85.20%,,27M,https://paperswithcode.com/paper/volo-vision-outlooker-for-visual-recognition,2021,,Sea AI Lab,National University of Singapore
79,ResNeXt-101 32x32d,Exploring the Limits of Weakly Supervised Pretraining,85.10%,97.50%,466M,https://paperswithcode.com/paper/exploring-the-limits-of-weakly-supervised,2018,ResNeXt,Facebook ,
80,ResNet200_vd_26w_4s_ssld,Semi-Supervised Recognition under a Noisy and Fine-grained Dataset,85.10%,97.40%,76M,https://paperswithcode.com/paper/semi-supervised-recognition-under-a-noisy-and,2020,ResNet,Baidu Inc.,
81,NFNet-F2,High-Performance Large-Scale Image Recognition Without Normalization,85.10%,97.30%,193.8M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
82,EfficientNetV2-M,EfficientNetV2: Smaller Models and Faster Training,85.10%,,55M,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster,2021,EfficientNet,Google Brain,
83,CAIT-S-24,Going deeper with Image Transformers,85.10%,,46.9M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
84,XCiT-S12,XCiT: Cross-Covariance Image Transformers,85.10%,,,https://paperswithcode.com/paper/xcit-cross-covariance-image-transformers,2021,,Facebook AI Research,"Inria, Sorbonne University"
85,FixEfficientNet-B3,Fixing the train-test resolution discrepancy: FixEfficientNet,85%,97.40%,12M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
86,EfficientNet-B7,RandAugment: Practical automated data augmentation with a reduced search space,85%,,66M,https://paperswithcode.com/paper/randaugment-practical-data-augmentation-with,2019,EfficientNet,Google Brain,
87,EfficientNetV2-S,EfficientNetV2: Smaller Models and Faster Training,85.00%,,24M,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster,2021,EfficientNet,Google Brain,
88,CvT-21,CvT: Introducing Convolutions to Vision Transformers,84.90%,,,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
89,ResNeXt-101 32x16d,Billion-scale semi-supervised learning for image classification,84.80%,97.40%,193M,https://paperswithcode.com/paper/billion-scale-semi-supervised-learning-for,2019,ResNeXt,Facebook AI Research,
90,MViT-B-24,Multiscale Vision Transformers,84.80%,,72.9M,https://paperswithcode.com/paper/multiscale-vision-transformers,2021,,Facebook AI Research,UC Berkeley
91,CAIT-XS-36,Going deeper with Image Transformers,84.80%,,38.6M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
92,NFNet-F1,High-Performance Large-Scale Image Recognition Without Normalization,84.70%,97.10%,132.6M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
93,BoTNet T7,Bottleneck Transformers for Visual Recognition,84.70%,97%,75.1M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
94,ResNeSt-269,ResNeSt: Split-Attention Networks,84.50%,,,https://paperswithcode.com/paper/resnest-split-attention-networks,2020,,"Snap, Amazon, ByteDance, SenseTime",UC Davis
95,EfficientNet-B7,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,84.40%,97.10%,66M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Google Brain,
96,GPIPE,GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism,84.40%,97%,,https://paperswithcode.com/paper/gpipe-efficient-training-of-giant-neural,2018,,Google ,
97,ResNet-RS-50,Revisiting ResNets: Improved Training and Scaling Strategies,84.40%,,192M,https://paperswithcode.com/paper/revisiting-resnets-improved-training-and,2021,ResNet,Google Brain,
98,ResMLP-B24/8,ResMLP: Feedforward networks for image classification with data-efficient training,84.40%,,116M,https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image,2021,MLP,"Facebook AI Research, Valeo","Inria, Sorbonne University"
99,ResNeXt-101 32x8d,Billion-scale semi-supervised learning for image classification,84.30%,97.20%,88M,https://paperswithcode.com/paper/billion-scale-semi-supervised-learning-for,2019,ResNeXt,Facebook AI Research,
100,TResNet-XL,TResNet: High Performance GPU-Dedicated Architecture,84.30%,,77M,https://paperswithcode.com/paper/tresnet-high-performance-gpu-dedicated,2020,,Alibaba,Damo Academy
101,LambdaResNet200,LambdaNetworks: Modeling Long-Range Interactions Without Attention,84.30%,,42M,https://paperswithcode.com/paper/lambdanetworks-modeling-long-range-1,2021,,Google Brain,
102,ResNeXt-101 32×16d,Exploring the Limits of Weakly Supervised Pretraining,84.20%,97.20%,194M,https://paperswithcode.com/paper/exploring-the-limits-of-weakly-supervised,2018,ResNeXt,Facebook ,
103,BoTNet T7-320,Bottleneck Transformers for Visual Recognition,84.20%,96.90%,75.1M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
104,DeiT-B,Training data-efficient image transformers & distillation through attention,84.20%,,86M,https://paperswithcode.com/paper/training-data-efficient-image-transformers,2020,Transformer,Facebook AI Research,Sorbonne University
105,Assemble-ResNet152,Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network,84.20%,,,https://paperswithcode.com/paper/compounding-the-performance-improvements-of,2020,ResNet,Naver Corp.,
106,Swin-B,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,84.20%,,,https://paperswithcode.com/paper/swin-transformer-hierarchical-vision,2021,Transformer,Microsoft Asia,"University of Science and Technology China, Tsinghua University, Xian Jiao Tong University"
107,ViP-B|384,Visual Parser: Representing Part-whole Hierarchies with Transformers,84.20%,,,https://paperswithcode.com/paper/visual-parser-representing-part-whole,2021,,ByteDance,University of Oxford
108,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,84.10%,96.90%,12M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
109,CAIT-XS-24,Going deeper with Image Transformers,84.10%,,26.6M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
110,Conformer-B,Conformer: Local Features Coupling Global Representations for Visual Recognition,84.1,,,https://paperswithcode.com/paper/conformer-local-features-coupling-global,2021,Transformer,Huawei Inc.,University of Chinese Academy of Sciences
111,Fix_ResNet50_vd_ssld,Semi-Supervised Recognition under a Noisy and Fine-grained Dataset,84.00%,97.00%,25.58M,https://paperswithcode.com/paper/semi-supervised-recognition-under-a-noisy-and,2020,ResNet,Baidu Inc.,
112,FixEfficientNetB4,Fixing the train-test resolution discrepancy: FixEfficientNet,84.00%,97.00%,19M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
113,EfficientNet-B6,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,84%,96.90%,43M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Google Brain,
114,BoTNet T6,Bottleneck Transformers for Visual Recognition,84%,96.70%,53.9M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
115,PiT-B,Rethinking Spatial Dimensions of Vision Transformers,84%,,73.8M,https://paperswithcode.com/paper/rethinking-spatial-dimensions-of-vision,2021,Transformer,Naver Corp.,Sogang University
116,LambdaResNet152,LambdaNetworks: Modeling Long-Range Interactions Without Attention,84.00%,,35M,https://paperswithcode.com/paper/lambdanetworks-modeling-long-range-1,2021,ResNet,Google Brain,
117,AmoebaNet-A,Regularized Evolution for Image Classifier Architecture Search,83.90%,96.60%,469M,https://paperswithcode.com/paper/regularized-evolution-for-image-classifier,2018,,Google Brain,
118,TNT-B,Transformer in Transformer,83.90%,,65.6M,https://paperswithcode.com/paper/transformer-in-transformer,2021,Transformer,Huawei Inc.,"University of Macau, "
119,DynamicViT-LV-M/0.8,DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification,83.9,,57.1M,https://paperswithcode.com/paper/dynamicvit-efficient-vision-transformers-with,2021,Transformer,,"Tsinghua University, University of Washington, UCLA"
120,EfficientNetV2-S,EfficientNetV2: Smaller Models and Faster Training,83.90%,,24M,https://paperswithcode.com/paper/efficientnetv2-smaller-models-and-faster,2021,EfficientNet,Google Brain,
121,ResNeSt-200,ResNeSt: Split-Attention Networks,83.90%,,,https://paperswithcode.com/paper/resnest-split-attention-networks,2020,,"Snap, Amazon, ByteDance, SenseTime, Facebook",UC Davis
122,SENet-350,Bottleneck Transformers for Visual Recognition,83.80%,96.60%,,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
123,PVTv2-B4,PVTv2: Improved Baselines with Pyramid Vision Transformer,83.80%,,82M,https://paperswithcode.com/paper/pvtv2-improved-baselines-with-pyramid-vision,2021,,"IIAI, SenseTime","Nanjing University, The University of Hong Kong, Nanjing University of Science and Technology"
124,Transformer local-attention,Aggregating Nested Transformers,83.80%,,68M,https://paperswithcode.com/paper/aggregating-nested-transformers,2021,Transformer,Google,Rutgers University
125,ResNet-RS-270,Revisiting ResNets: Improved Training and Scaling Strategies,83.80%,,,https://paperswithcode.com/paper/revisiting-resnets-improved-training-and,2021,ResNet,Google Brain,
126,FixPNASNet-5,Fixing the train-test resolution discrepancy,83.70%,96.80%,86.1M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy,2019,,Facebook AI Research,
127,Twins-SVT-L,Twins: Revisiting the Design of Spatial Attention in Vision Transformers,83.70%,,99.2M,https://paperswithcode.com/paper/twins-revisiting-spatial-attention-design-in,2021,Transformer,Meituan Inc.,The University of Adelaide
128,FixEfficientNet-B2,Fixing the train-test resolution discrepancy: FixEfficientNet,83.60%,96.90%,9.2M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
129,NFNet-F0,High-Performance Large-Scale Image Recognition Without Normalization,83.60%,96.80%,71.5M,https://paperswithcode.com/paper/high-performance-large-scale-image,2021,,DeepMind,
130,MultiGrain PNASNet,MultiGrain: a unified image embedding for classes and instances,83.60%,96.70%,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
131,ResT-Large,ResT: An Efficient Transformer for Visual Recognition,83.60%,96.30%,51.63M,https://paperswithcode.com/paper/rest-an-efficient-transformer-for-visual,2021,Transformer,,Nanjing University
132,ResMLP-B24/8,ResMLP: Feedforward networks for image classification with data-efficient training,83.60%,,116M,https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image,2021,MLP,"Facebook AI Research, Valeo","Inria, Sorbonne University"
133,ViTAE-B-Stage,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,83.60%,,48.5M,https://paperswithcode.com/paper/vitae-vision-transformer-advanced-by,2021,,JD Explore,University of Sydney
134,VIT-B,Masked Autoencoders Are Scalable Vision Learners,83.6,,,https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision,2021,,Facebook AI Research,
135,BoTNet T5,Bottleneck Transformers for Visual Recognition,83.50%,96.50%,75.1M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
136,ResNeXt-101 32x4d,Billion-scale semi-supervised learning for image classification,83.40%,96.80%,42M,https://paperswithcode.com/paper/billion-scale-semi-supervised-learning-for,2019,ResNeXt,Facebook AI Research,
137,sMLPNet-B,Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?,83.40%,,65.9M,https://paperswithcode.com/paper/sparse-mlp-for-image-recognition-is-self,2021,MLP,Microsoft Asia,University of Science and Technology of Hefei
138,ResNet-RS,Revisiting ResNets: Improved Training and Scaling Strategies,83.40%,,,https://paperswithcode.com/paper/revisiting-resnets-improved-training-and,2021,ResNet,Google Brain,
139,"SE-ResNeXt-101, 64x4d, S=2",Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training,83.34%,96.61%,,https://paperswithcode.com/paper/splitnet-divide-and-co-training,2020,ResNeXt,,"Shenzhen Institute of Artificial Intelligence and Robotics for Society, Zhejiang University"
140,EfficientNet-B5,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,83.30%,96.70%,30M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Google Brain,
141,CeiT-S,Incorporating Convolution Designs into Visual Transformers,83.30%,96.50%,,https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual,2021,Transformer,SenseTime ,"Nanyang Technological University, HKUST"
142,ViL-Medium-D,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,83.30%,,39.7M,https://paperswithcode.com/paper/2103-15358,2021,Transformer,Microsoft ,
143,Transformer local-attention,Aggregating Nested Transformers,83.30%,,38M,https://paperswithcode.com/paper/aggregating-nested-transformers,2021,Transformer,Google,Rutgers University
144,CvT-21,CvT: Introducing Convolutions to Vision Transformers,83.30%,,32M,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
145,T2T-ViT-14|384,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,83.30%,,,https://paperswithcode.com/paper/tokens-to-token-vit-training-vision,2021,Transformer,YITU Technology,National University of Singapore
146,ResNet-50,Meta Pseudo Labels,83.20%,96.5,,https://paperswithcode.com/paper/meta-pseudo-labels,2020,ResNet,Google Brain,
147,CycleMLP-B5,CycleMLP: A MLP-like Architecture for Dense Prediction,83.20%,,76M,https://paperswithcode.com/paper/cyclemlp-a-mlp-like-architecture-for-dense,2021,MLP,SenseTime ,The University of Hong Kong
148,ViL-Base-D,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,83.20%,,55.7M,https://paperswithcode.com/paper/2103-15358,2021,Transformer,Microsoft,International Digital Economy Academy
149,PVTv2-B3,PVTv2: Improved Baselines with Pyramid Vision Transformer,83.20%,,45.2M,https://paperswithcode.com/paper/pvtv2-improved-baselines-with-pyramid-vision,2021,,"IIAI, SenseTime","Nanjing University, The University of Hong Kong, Nanjing University of Science and Technology"
150,MultiGrain PNASNet,MultiGrain: a unified image embedding for classes and instances,83.20%,,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
151,sMLPNet-S,Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?,83.10%,,48.6M,https://paperswithcode.com/paper/sparse-mlp-for-image-recognition-is-self,2021,MLP,Microsoft Asia,University of Science and Technology of Hefei
152,MultiGrain SENet154,MultiGrain: a unified image embedding for classes and instances,83.10%,,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
153,DeepVit-L*,DeepViT: Towards Deeper Vision Transformer,83.10%,,,https://paperswithcode.com/paper/deepvit-towards-deeper-vision-transformer,2021,Transformer,ByteDance,National University of Singapore
154,MultiGrain SENet154,MultiGrain: a unified image embedding for classes and instances,83.00%,96.50%,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
155,ResNet50_vd_ssld,Semi-Supervised Recognition under a Noisy and Fine-grained Dataset,83.00%,96.40%,25.58M,https://paperswithcode.com/paper/semi-supervised-recognition-under-a-noisy-and,2020,ResNet,Baidu Inc.,
156,MViT-B-16,Multiscale Vision Transformers,83.00%,,37.0M,https://paperswithcode.com/paper/multiscale-vision-transformers,2021,,Facebook AI Research,UC Berkeley
157,ResNeSt-101,ResNeSt: Split-Attention Networks,83.00%,,,https://paperswithcode.com/paper/resnest-split-attention-networks,2020,,"Snap, Amazon, ByteDance, SenseTime",UC Davis
158,CvT-13,CvT: Introducing Convolutions to Vision Transformers,83%,,,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
159,Oct-ResNet-152,Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution,82.90%,96.30%,67M,https://paperswithcode.com/paper/drop-an-octave-reducing-spatial-redundancy-in,2019,,"YITU Technology, Facebook AI Research",National University of Singapore
160,PNASNet-5,Progressive Neural Architecture Search,82.90%,96.20%,86.1M,https://paperswithcode.com/paper/progressive-neural-architecture-search,2017,,Google AI,"Johns Hopkins University, Stanford University"
161,GFNet-H-B,Global Filter Networks for Image Classification,82.90%,96.20%,54M,https://paperswithcode.com/paper/global-filter-networks-for-image,2021,,,Tsinghua University
162,ViL-Medium-W,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,82.90%,,39.8M,https://paperswithcode.com/paper/2103-15358,2021,Transformer,Microsoft,International Digital Economy Academy
163,BoTNet T4,Bottleneck Transformers for Visual Recognition,82.80%,96.30%,54.7M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
164,CrossViT-18+,CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification,82.80%,,44.3M,https://paperswithcode.com/paper/2103-14899,2021,Transformer,IBM,MIT
165,FunMatch - T384+224,Knowledge distillation: A good teacher is patient and consistent,82.80%,,,https://paperswithcode.com/paper/knowledge-distillation-a-good-teacher-is,2021,,Google Brain,
166,CCT-14/7x2 | 384,Escaping the Big Data Paradigm with Compact Transformers,82.71%,,,https://paperswithcode.com/paper/escaping-the-big-data-paradigm-with-compact,2021,,PicsArt Inc.,"University of Oregon, UIUC"
167,NASNET-A,Learning Transferable Architectures for Scalable Image Recognition,82.70%,96.20%,88.9M,https://paperswithcode.com/paper/learning-transferable-architectures-for,2017,,Google Brain,
168,Container,Container: Context Aggregation Network,82.70%,,22.1M,https://paperswithcode.com/paper/container-context-aggregation-network,2021,,SenseTime,"University of Washington, CUHK"
169,MultiGrain SENet154,MultiGrain: a unified image embedding for classes and instances,82.70%,,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
170,Harm-SE-RNX-101 64x4d,Harmonic Convolutional Networks based on Discrete Cosine Transform,82.66%,96.29%,88.2M,https://paperswithcode.com/paper/harmonic-convolutional-networks-based-on,2020,,,"Trinity College, Dublin City University"
171,FixEfficientNet-B1,Fixing the train-test resolution discrepancy: FixEfficientNet,82.60%,96.50%,7.8M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
172,EfficientNet-B4,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,82.60%,96.30%,19M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Google Brain,
173,RVT-B*,Towards Robust Vision Transformer,82.60%,96%,91.8M,https://paperswithcode.com/paper/rethinking-the-design-principles-of-robust,2021,Transformer,Alibaba ,Swinburne University of Technology
174,T2T-ViTt-24,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,82.60%,,64.4M,https://paperswithcode.com/paper/tokens-to-token-vit-training-vision,2021,Transformer,YITU Technology,National University of Singapore
175,DeiT-S,Training data-efficient image transformers & distillation through attention,82.60%,,22M,https://paperswithcode.com/paper/training-data-efficient-image-transformers,2020,Transformer,Facebook AI Research,Sorbonne University
176,MultiGrain PNASNet,MultiGrain: a unified image embedding for classes and instances,82.60%,,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
177,FixResNet-50 Billion,Fixing the train-test resolution discrepancy,82.50%,96.60%,,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy,2019,ResNet,Facebook AI Research,
178,ConViT-B+,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,82.50%,,152M,https://paperswithcode.com/paper/convit-improving-vision-transformers-with,2021,Transformer,Facebook AI Research,Ecole Normale
179,MetaFormer PoolFormer-M48,MetaFormer is Actually What You Need for Vision,82.50%,,73M,https://paperswithcode.com/paper/metaformer-is-actually-what-you-need-for,2021,,Sea AI Lab,National University of Singapore
180,CrossViT-18,CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification,82.50%,,43.3M,https://paperswithcode.com/paper/2103-14899,2021,Transformer,IBM,MIT
181,CvT-21,CvT: Introducing Convolutions to Vision Transformers,82.50%,,,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
182,LeViT-384,LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference,82.50%,,,https://paperswithcode.com/paper/levit-a-vision-transformer-in-convnet-s,2021,Transformer,Facebook AI Research,
183,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,82.40%,96.30%,9.2M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
184,DeiT-B with iRPE-K,Rethinking and Improving Relative Position Encoding for Vision Transformer,82.40%,,87M,https://paperswithcode.com/paper/rethinking-and-improving-relative-position,2021,Transformer,Microsoft Asia,SunYat-sen University
185,ConViT-B,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,82.40%,,86M,https://paperswithcode.com/paper/convit-improving-vision-transformers-with,2021,Transformer,Facebook AI Research,Ecole Normale
186,ResNet-152,ResNet strikes back: An improved training procedure in timm,82.40%,,60.2M,https://paperswithcode.com/paper/resnet-strikes-back-an-improved-training,2021,,Facebook AI Research,Sorbonne University
187,AutoFormer-base,AutoFormer: Searching Transformers for Visual Recognition,82.40%,,54M,https://paperswithcode.com/paper/autoformer-searching-transformers-for-visual,2021,Transformer,Microsoft Asia,Stony Brook University
188,T2T-ViTt-19,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,82.40%,,39.2M,https://paperswithcode.com/paper/tokens-to-token-vit-training-vision,2021,Transformer,YITU Technology,National University of Singapore
189,ColorNet,ColorNet: Investigating the importance of color spaces for image classification,82.35%,94.78%,,https://paperswithcode.com/paper/colornet-investigating-the-importance-of,2019,,,Tsinghua University
190,SCARLET-A4,SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search,82.30%,96%,27.8M,https://paperswithcode.com/paper/scarletnas-bridging-the-gap-between,2019,,Xiaomi,
191,GLiT-Bases,GLiT: Neural Architecture Search for Global and Local Image Transformer,82.30%,,96.1M,https://paperswithcode.com/paper/glit-neural-architecture-search-for-global,2021,,SenseTime,"University of Sydney, University of Oxford"
192,T2T-ViT-24,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,82.30%,,64.4M,https://paperswithcode.com/paper/tokens-to-token-vit-training-vision,2021,Transformer,YITU Technology,National University of Singapore
193,CrossViT-15+,CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification,82.30%,,28.2M,https://paperswithcode.com/paper/2103-14899,2021,Transformer,IBM,MIT
194,ResNeXt-101 32x8d,Exploring the Limits of Weakly Supervised Pretraining,82.20%,96.40%,88M,https://paperswithcode.com/paper/exploring-the-limits-of-weakly-supervised,2018,ResNeXt,Facebook,
195,SENet-152,Bottleneck Transformers for Visual Recognition,82.20%,95.90%,66.6M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,,Google,UC Berkeley
196,BossNet-T1+,BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search,82.20%,95.7,,https://paperswithcode.com/paper/bossnas-exploring-hybrid-cnn-transformers,2021,Transformer,Alibaba,"Monash University, University of Oxford, RMIT University, SunYat-sen University"
197,DeepVit-L,DeepViT: Towards Deeper Vision Transformer,82.20%,,55M,https://paperswithcode.com/paper/deepvit-towards-deeper-vision-transformer,2021,Transformer,ByteDance,National University of Singapore
198,ConViT-S+,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,82.20%,,48M,https://paperswithcode.com/paper/convit-improving-vision-transformers-with,2021,Transformer,Facebook AI Research,Ecole Normale
199,ViTAE-S-Stage,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,82.20%,,19.2M,https://paperswithcode.com/paper/vitae-vision-transformer-advanced-by,2021,,JD Explore,University of Sydney
200,CAIT-XXS-36,Going deeper with Image Transformers,82.20%,,17.3M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
201,CvT-13-NAS,CvT: Introducing Convolutions to Vision Transformers,82.20%,,,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
202,Evo-LeViT-384*,Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer,82.20%,,,https://paperswithcode.com/paper/evo-vit-slow-fast-token-evolution-for-dynamic,2021,,,"Shanghai Jiao Tong University, University of Chinese Academy of Sciences"
203,"ResNeXt-101, 64x4d, S=2",Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training,82.13%,95.98%,,https://paperswithcode.com/paper/splitnet-divide-and-co-training,2020,ResNeXt,,"The Chinese University of Hong Kong, Shenzhen Institute of Artificial Intelligence and Robotics for Society"
204,CeiT-S,Incorporating Convolution Designs into Visual Transformers,82%,95.90%,24.2M,https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual,2021,Transformer,SenseTime ,Nanyang Technological University
205,PVTv2-B2,PVTv2: Improved Baselines with Pyramid Vision Transformer,82%,,25.4M,https://paperswithcode.com/paper/pvtv2-improved-baselines-with-pyramid-vision,2021,,"IIAI, SenseTime","Nanjing University, The University of Hong Kong, Nanjing University of Science and Technology"
206,ViL-Small,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,82%,,24.6M,https://paperswithcode.com/paper/2103-15358,2021,Transformer,Microsoft,International Digital Economy Academy
207,Container-Light,Container: Context Aggregation Network,82%,,20M,https://paperswithcode.com/paper/container-context-aggregation-network,2021,,SenseTime,"University of Washington, Shanghai AI Lab"
208,DIFFQ,Differentiable Model Compression via Pseudo Quantization Noise,82,,,https://paperswithcode.com/paper/differentiable-model-compression-via-pseudo,2021,,Facebook AI Research,
209,RVT-S*,Towards Robust Vision Transformer,81.90%,95.80%,23.3M,https://paperswithcode.com/paper/rethinking-the-design-principles-of-robust,2021,Transformer,Alibaba ,Swinburne University of Technology
210,ViL-Base-W,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,81.90%,,79M,https://paperswithcode.com/paper/2103-15358,2021,Transformer,Microsoft,International Digital Economy Academy
211,sMLPNet-T,Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?,81.90%,,24.1M,https://paperswithcode.com/paper/sparse-mlp-for-image-recognition-is-self,2021,MLP,Microsoft Asia,University of Science and Technology of Hefei
212,PiT-S,Rethinking Spatial Dimensions of Vision Transformers,81.90%,,23.5M,https://paperswithcode.com/paper/rethinking-spatial-dimensions-of-vision,2021,Transformer,Naver Corp.,Sogang University
213,T2T-ViT-19,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,81.90%,,,https://paperswithcode.com/paper/tokens-to-token-vit-training-vision,2021,Transformer,YITU Technology,National University of Singapore
214,AOGNet-40M-AN,Attentive Normalization,81.87%,95.74%,,https://paperswithcode.com/paper/attentive-normalization,2019,,,NC State University
215,ResNet-152,ResNet strikes back: An improved training procedure in timm,81.80%,,60.2M,https://paperswithcode.com/paper/resnet-strikes-back-an-improved-training,2021,,Facebook AI Research,Sorbonne University
216,ResNet-200,Parametric Contrastive Learning,81.80%,,,https://paperswithcode.com/paper/parametric-contrastive-learning,2021,ResNet,SmartMore,The Chinese University of Hong Kong
217,FBNetV5,FBNetV5: Neural Architecture Search for Multiple Tasks in One Run,81.80%,,,https://paperswithcode.com/paper/fbnetv5-neural-architecture-search-for,2021,,Facebook ,Rice University
218,BoTNet T3,Bottleneck Transformers for Visual Recognition,81.70%,95.80%,33.5M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,Transformer,Google,UC Berkeley
219,AutoFormer-small,AutoFormer: Searching Transformers for Visual Recognition,81.70%,95.7,22.9M,https://paperswithcode.com/paper/autoformer-searching-transformers-for-visual,2021,Transformer,Microsoft Asia,Stony Brook University
220,T2T-ViT-14,Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks,81.70%,,,https://paperswithcode.com/paper/beyond-self-attention-external-attention,2021,Transformer,,Tsinghua University
221,ResNet-152,Sharpness-Aware Minimization for Efficiently Improving Generalization,81.60%,95.65,,https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1,2020,ResNet,Google,
222,gMLP-B,Pay Attention to MLPs,81.6,,73M,https://paperswithcode.com/paper/pay-attention-to-mlps,2021,MLP,Google Brain,
223,CvT-13,CvT: Introducing Convolutions to Vision Transformers,81.60%,,,https://paperswithcode.com/paper/cvt-introducing-convolutions-to-vision,2021,Transformer,Microsoft Cloud AI,McGill University
224,LeViT-256,LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference,81.60%,,,https://paperswithcode.com/paper/levit-a-vision-transformer-in-convnet-s,2021,Transformer,Facebook,
225,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,81.50%,95.80%,7.8M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,Carnegie Mellon University
226,Visformer-S,Visformer: The Vision-friendly Transformer,81.50%,,40.2M,https://paperswithcode.com/paper/visformer-the-vision-friendly-transformer,2021,Transformer,,"Beihang University, Johns Hopkins University, University of Science and Technology China, Xidian University, Zhengzhou University"
227,CrossViT-15,CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification,81.50%,,27.4M,https://paperswithcode.com/paper/2103-14899,2021,Transformer,IBM,MIT
228,T2T-ViT-14,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,81.50%,,21.5M,https://paperswithcode.com/paper/tokens-to-token-vit-training-vision,2021,Transformer,YITU Technology,National University of Singapore
229,Transformer local-attention,Aggregating Nested Transformers,81.50%,,17M,https://paperswithcode.com/paper/aggregating-nested-transformers,2021,Transformer,Google,Rutgers University
230,CoE-Large 214 MFLOPs,Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs,81.50%,,,https://paperswithcode.com/paper/collaboration-of-experts-achieving-80-top-1,2021,,Huawei Inc.,
231,PyConvResNet-101,Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition,81.49%,95.72%,42.3M,https://paperswithcode.com/paper/pyramidal-convolution-rethinking,2020,,IIAI,
232,SENet-101,Bottleneck Transformers for Visual Recognition,81.40%,95.70%,49.2M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,,Google,UC Berkeley
233,DeiT-S with iRPE-QKV,Rethinking and Improving Relative Position Encoding for Vision Transformer,81.40%,,22M,https://paperswithcode.com/paper/rethinking-and-improving-relative-position,2021,Transformer,Microsoft Asia,SunYat-sen University
234,DPN-131,Dual Path Networks,81.38%,95.77%,80M,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
235,ResNet-200,Adversarial AutoAugment,81.32%,95.30%,,https://paperswithcode.com/paper/adversarial-autoaugment-1,2019,ResNet,Huawei Inc.,
236,ResNet-152,Parametric Contrastive Learning,81.30%,95.4,,https://paperswithcode.com/paper/parametric-contrastive-learning,2021,ResNet,SmartMore,The Chinese University of Hong Kong
237,ConViT-S,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,81.30%,,27M,https://paperswithcode.com/paper/convit-improving-vision-transformers-with,2021,Transformer,Facebook AI Research,Ecole Normale
238,MultiGrain PNASNet,MultiGrain: a unified image embedding for classes and instances,81.30%,,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
239,DPN-98,Dual Path Networks,81.28%,95.60%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
240,Res2Net-101,Res2Net: A New Multi-scale Backbone Architecture,81.23%,94.43%,,https://paperswithcode.com/paper/res2net-a-new-multi-scale-backbone,2019,,,"Nankai University, University of Oxford, UC Merced"
241,ResNet-50,Billion-scale semi-supervised learning for image classification,81.20%,,,https://paperswithcode.com/paper/billion-scale-semi-supervised-learning-for,2019,ResNet,Facebook AI Research,
242,ResNeXt-101,Shape-Texture Debiased Neural Network Training,81.2,,,https://paperswithcode.com/paper/shape-texture-debiased-neural-network-1,2020,ResNeXt,Google Brain,"Johns Hopkins University, Shanghai Jiao Tong University, University of California SantaCruz"
243,EfficientNet-B3,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,81.10%,95.50%,12M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Google Brain,
244,ResNet-152x2-SAM,When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations,81.10%,,236M,https://paperswithcode.com/paper/when-vision-transformers-outperform-resnets,2021,ResNet,Google Brain,UCLA
245,DeiT-S with iRPE-QK,Rethinking and Improving Relative Position Encoding for Vision Transformer,81.10%,,22M,https://paperswithcode.com/paper/rethinking-and-improving-relative-position,2021,Transformer,Microsoft Asia,SunYat-sen University
246,DPN-98,Dual Path Networks,81.06%,95.56%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
247,ViTAE-13M,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,81%,,13.2M,https://paperswithcode.com/paper/vitae-vision-transformer-advanced-by,2021,,JD Explore,University of Sydney
248,DPN-92,Dual Path Networks,80.96%,95.47%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
249,ResNeXt-101  64x4,Aggregated Residual Transformations for Deep Neural Networks,80.90%,95.60%,83.6M,https://paperswithcode.com/paper/aggregated-residual-transformations-for-deep,2016,ResNeXt,Facebook AI Research,UC San Diego
250,ResNet-101,Parametric Contrastive Learning,80.90%,95.2,,https://paperswithcode.com/paper/parametric-contrastive-learning,2021,ResNet,SmartMore,The Chinese University of Hong Kong
251,CentroidViT-S,Centroid Transformers: Learning to Abstract with Attention,80.9,,22.3M,https://paperswithcode.com/paper/centroid-transformers-learning-to-abstract,2021,Transformer,,UT Austin
252,DeiT-S with iRPE-K,Rethinking and Improving Relative Position Encoding for Vision Transformer,80.90%,,22M,https://paperswithcode.com/paper/rethinking-and-improving-relative-position,2021,Transformer,Microsoft Asia,SunYat-sen University
253,CAIT-XXS-24,Going deeper with Image Transformers,80.90%,,12M,https://paperswithcode.com/paper/going-deeper-with-image-transformers,2021,Transformer,Facebook AI Research,Sorbonne University
254,ResNet-200,Supervised Contrastive Learning,80.80%,95.60%,,https://paperswithcode.com/paper/supervised-contrastive-learning,2020,ResNet,"Google, Snap","MIT, Boston University"
255,LocalViT-S,LocalViT: Bringing Locality to Vision Transformers,80.80%,95.40%,,https://paperswithcode.com/paper/localvit-bringing-locality-to-vision,2021,Transformer,,"ETH Zurich, KU Leuven"
256,ResMLP-S24,ResMLP: Feedforward networks for image classification with data-efficient training,80.80%,,30M,https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image,2021,,"Facebook AI Research, Valeo","Inria, Sorbonne University"
257,CoE-Large 194 MFLOPs,Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs,80.70%,,,https://paperswithcode.com/paper/collaboration-of-experts-achieving-80-top-1,2021,,Huawei Inc.,
258,ResNet-50 + MEAL V2,MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks,80.67,,,https://paperswithcode.com/paper/meal-v2-boosting-vanilla-resnet-50-to-80-top,2020,ResNet,,Carnegie Mellon University
259,DPN-92,Dual Path Networks,80.66%,95.34%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
260,HCGNet-C,Gated Convolutional Networks with Hybrid Connectivity for Image Classification,80.64%,95.07%,,https://paperswithcode.com/paper/gated-convolutional-networks-with-hybrid,2019,,,University of Chinese Academy of Sciences 
261,ResNet-200,Fast AutoAugment,80.60%,95.30%,,https://paperswithcode.com/paper/fast-autoaugment,2019,ResNet,Kakao Brain,
262,ResNeXt-101,CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features,80.53%,94.97%,,https://paperswithcode.com/paper/cutmix-regularization-strategy-to-train,2019,ResNeXt,Naver Corp.,Yonsei University
263,NAT-M4,Neural Architecture Transfer,80.50%,95.20%,9.1M,https://paperswithcode.com/paper/neural-architecture-transfer,2020,,,"Southern University of Science and Technology, Michigan State University"
264,Attention-92,Residual Attention Network for Image Classification,80.50%,95.20%,,https://paperswithcode.com/paper/residual-attention-network-for-image,2017,,SenseTime,"Tsinghua University, The Chinese University of Hong Kong"
265,GLiT-Smalls,GLiT: Neural Architecture Search for Global and Local Image Transformer,80.50%,,24.6M,https://paperswithcode.com/paper/glit-neural-architecture-search-for-global,2021,,"SenseTime, Baidu Inc.","University of Sydney, University of Oxford"
266,DVT,Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition,80.43%,,,https://paperswithcode.com/paper/not-all-images-are-worth-16x16-words-dynamic,2021,Transformer,Huawei Inc.,"Beijing Academy of Intelligence, Tsinghua University"
267,ResNet50,ResNet strikes back: An improved training procedure in timm,80.40%,,25M,https://paperswithcode.com/paper/resnet-strikes-back-an-improved-training,2021,,Facebook AI Research,Sorbonne University
268,DeiT-S,ResNet strikes back: An improved training procedure in timm,80.40%,,22M,https://paperswithcode.com/paper/resnet-strikes-back-an-improved-training,2021,,Facebook AI Research,Sorbonne University
269,ResNet-50+AutoDropout+RandAugment,AutoDropout: Learning Dropout Patterns to Regularize Deep Networks,80.30%,,,https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to,2021,ResNet,Google Brain,Carnegie Mellon University
270,CCT-16/7x2,Escaping the Big Data Paradigm with Compact Transformers,80.28%,,,https://paperswithcode.com/paper/escaping-the-big-data-paradigm-with-compact,2021,,PicsArt Inc.,"University of Oregon, UIUC"
271,iAFF-ResNeXt-50-32x4d,Attentional Feature Fusion,80.22%,94.90%,34.7M,https://paperswithcode.com/paper/attentional-feature-fusion,2020,ResNeXt,,"Nanjing University of Aeronautics and Astronautics, University of Munster, University of Copenhagen, University of Arizona"
272,FixEfficientNet-B0,Fixing the train-test resolution discrepancy: FixEfficientNet,80.20%,95.40%,5.3M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy-2,2020,EfficientNet,Facebook AI Research,
273,ConvMLP-L,ConvMLP: Hierarchical Convolutional MLPs for Vision,80.20%,,42.7M,https://paperswithcode.com/paper/convmlp-hierarchical-convolutional-mlps-for,2021,,PicsArt Inc.,"University of Oregon, UIUC"
274,Inception ResNet V2,"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",80.10%,95.10%,55.8M,https://paperswithcode.com/paper/inception-v4-inception-resnet-and-the-impact,2016,ResNet,Google,
275,RandWire-WS,Exploring Randomly Wired Neural Networks for Image Recognition,80.10%,94.80%,,https://paperswithcode.com/paper/exploring-randomly-wired-neural-networks-for,2019,,Facebook AI Research,
276,WideNet-H,Go Wider Instead of Deeper,80.09%,,63M,https://paperswithcode.com/paper/go-wider-instead-of-deeper,2021,,,National University of Singapore
277,DPN-131,Dual Path Networks,80.07%,94.88%,80M,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
278,ResNet-101,Bottleneck Transformers for Visual Recognition,80%,95%,44.4M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,ResNet,Google,UC Berkeley
279,LeViT-192,LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference,80%,,,https://paperswithcode.com/paper/levit-a-vision-transformer-in-convnet-s,2021,Transformer,Facebook,
280,CoE-Small 100 MFLOPs,Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs,80%,,,https://paperswithcode.com/paper/collaboration-of-experts-achieving-80-top-1,2021,,Huawei Inc.,
281,DPN-98,Dual Path Networks,79.95%,94.85%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
282,ScaleNet-152,Data-Driven Neuron Allocation for Scale Aggregation Networks,79.94%,94.82%,,https://paperswithcode.com/paper/190409460,2019,,SenseTime,
283,ResNet-200,Identity Mappings in Deep Residual Networks,79.90%,95.20%,,https://paperswithcode.com/paper/identity-mappings-in-deep-residual-networks,2016,ResNet,Microsoft,
284,ViT-B/16-SAM,When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations,79.90%,,87M,https://paperswithcode.com/paper/when-vision-transformers-outperform-resnets,2021,Transformer,Google Brain,UCLA
285,RegNetY-8.0GF,Designing Network Design Spaces,79.90%,,39.2M,https://paperswithcode.com/paper/designing-network-design-spaces,2020,,Facebook AI Research,
286,SKNet-101,Selective Kernel Networks,79.81%,,48.9M,https://paperswithcode.com/paper/selective-kernel-networks,2019,,Momenta,"Nanjing University, Nanjing University of Science and Technology, Tsinghua University"
287,CSPResNeXt-50,CSPNet: A New Backbone that can Enhance Learning Capability of CNN,79.80%,95.20%,20.5M,https://paperswithcode.com/paper/cspnet-a-new-backbone-that-can-enhance,2019,,,National Chiao Tung University
288,CSPResNeXt-50 + Mish,Mish: A Self Regularized Non-Monotonic Activation Function,79.80%,95.20%,,https://paperswithcode.com/paper/mish-a-self-regularized-non-monotonic-neural,2019,,,KIIT
289,EfficientNet-B2,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,79.80%,94.90%,9.2M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Google Brain,
290,FixResNet-50 CutMix,Fixing the train-test resolution discrepancy,79.80%,94.90%,,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy,2019,ResNet,Facebook AI Research,
291,DVT,Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition,79.74%,,,https://paperswithcode.com/paper/not-all-images-are-worth-16x16-words-dynamic,2021,Transformer,Huawei Inc.,"Beijing Academy of Intelligence, Tsinghua University"
292,ResMLP-36,ResMLP: Feedforward networks for image classification with data-efficient training,79.70%,,45M,https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image,2021,,"Facebook AI Research, Valeo","Inria, Sorbonne University"
293,Grafit,Grafit: Learning fine-grained image representations with coarse labels,79.60%,,,https://paperswithcode.com/paper/grafit-learning-fine-grained-image,2020,ResNet,Facebook AI Research,Sorbonne University
294,LeViT-128,LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference,79.60%,,,https://paperswithcode.com/paper/levit-a-vision-transformer-in-convnet-s,2021,Transformer,Facebook,
295,WideNet-L,Go Wider Instead of Deeper,79.49%,,40M,https://paperswithcode.com/paper/go-wider-instead-of-deeper,2021,,,National University of Singapore
296,MultiGrain R50-AA-500,MultiGrain: a unified image embedding for classes and instances,79.40%,94.80%,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,Facebook AI Research,
297,SENet-50,Bottleneck Transformers for Visual Recognition,79.40%,94.60%,28.02M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,,Google,UC Berkeley
298,TinyNet,"Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets",79.40%,94.50%,11.9M,https://paperswithcode.com/paper/model-rubik-s-cube-twisting-resolution-depth,2020,,Huawei Inc.,
299,ResNet-50,Adversarial AutoAugment,79.40%,94.47%,,https://paperswithcode.com/paper/adversarial-autoaugment-1,2019,ResNet,"Facebook AI Research, Valeo","Inria, Sorbonne University"
300,ResMLP-24,ResMLP: Feedforward networks for image classification with data-efficient training,79.40%,,30M,https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image,2021,,Facebook AI Research,
301,RegNetY-4.0GF,Designing Network Design Spaces,79.40%,,20.6M,https://paperswithcode.com/paper/designing-network-design-spaces,2020,,,Nanjing University
302,LIP-ResNet-101,LIP: Local Importance-based Pooling,79.33%,94.60%,42.9M,https://paperswithcode.com/paper/lip-local-importance-based-pooling,2019,,ByteDance,Peking University
303,RedNet-152,Involution: Inverting the Inherence of Convolution for Visual Recognition,79.30%,,34M,https://paperswithcode.com/paper/involution-inverting-the-inherence-of,2021,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
304,DPN-92,Dual Path Networks,79.27%,94.63%,,https://paperswithcode.com/paper/dual-path-networks,2017,,LG CNS,Seoul National University of Science and Technology
305,PS-KD,Self-Knowledge Distillation with Progressive Refinement of Targets,79.24%,94.66%,,https://paperswithcode.com/paper/self-knowledge-distillation-a-simple-way-for,2020,ResNet,Alibaba ,Swinburne University of Technology
306,RVT-Ti*,Towards Robust Vision Transformer,79.20%,94.70%,10.9M,https://paperswithcode.com/paper/rethinking-the-design-principles-of-robust,2021,Transformer,Google Brain,Carnegie Mellon University
307,ResNet-101,Revisiting Unreasonable Effectiveness of Data in Deep Learning Era,79.20%,94.70%,,https://paperswithcode.com/paper/revisiting-unreasonable-effectiveness-of-data,2017,ResNet,Intel Corp.,Carnegie Mellon University
308,Multiscale DEQ,Multiscale Deep Equilibrium Models,79.20%,,,https://paperswithcode.com/paper/multiscale-deep-equilibrium-models,2020,,SenseTime,
309,ScaleNet-101,Data-Driven Neuron Allocation for Scale Aggregation Networks,79.18%,94.58%,,https://paperswithcode.com/paper/190409460,2019,,Facebook AI Research,
310,FixResNet-50,Fixing the train-test resolution discrepancy,79.10%,94.60%,25.6M,https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy,2019,ResNet,Google Brain,
311,AA-ResNet-152,Attention Augmented Convolutional Networks,79.10%,94.60%,,https://paperswithcode.com/paper/190409925,2019,,ByteDance,Peking University
312,RedNet-101,Involution: Inverting the Inherence of Convolution for Visual Recognition,79.10%,,25.6M,https://paperswithcode.com/paper/involution-inverting-the-inherence-of,2021,,Naver Corp.,Sogang University
313,PiT-XS,Rethinking Spatial Dimensions of Vision Transformers,79.10%,,10.6M,https://paperswithcode.com/paper/rethinking-spatial-dimensions-of-vision,2021,Transformer,Google Brain,Carnegie Mellon University
314,ResNet-50,Unsupervised Data Augmentation for Consistency Training,79.04%,,,https://paperswithcode.com/paper/unsupervised-data-augmentation-1,2019,ResNet,Google,
315,Xception,Xception: Deep Learning with Depthwise Separable Convolutions,79%,94.50%,22.8M,https://paperswithcode.com/paper/xception-deep-learning-with-depthwise,2016,,Baidu Inc.,
316,MobileNetV3_large_x1_0_ssld,Semi-Supervised Recognition under a Noisy and Fine-grained Dataset,79.00%,94.50%,5.47M,https://paperswithcode.com/paper/semi-supervised-recognition-under-a-noisy-and,2020,,Google Brain,
317,SpineNet-143,SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization,79%,94.40%,60.5M,https://paperswithcode.com/paper/spinenet-learning-scale-permuted-backbone-for,2019,,Google Brain,UCLA
318,Mixer-B/8-SAM,When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations,79%,,64M,https://paperswithcode.com/paper/when-vision-transformers-outperform-resnets,2021,,PicsArt Inc.,"University of Oregon, UIUC"
319,ConvMLP-M,ConvMLP: Hierarchical Convolutional MLPs for Vision,79%,,17.4M,https://paperswithcode.com/paper/convmlp-hierarchical-convolutional-mlps-for,2021,,Google,
320,InceptionV3,Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks,78.95%,94.49%,,https://paperswithcode.com/paper/filter-response-normalization-layer,2019,,Samsung,"Cornell University, Higher School of Economics, Lomonosov Moscow State University"
321,ResNet-152 + SWA,Averaging Weights Leads to Wider Optima and Better Generalization,78.94%,,,https://paperswithcode.com/paper/averaging-weights-leads-to-wider-optima-and,2018,ResNet,,"Tianjin University, Dalian University of Technology, Harbin Institute of Technology"
322,ECA-Net,ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks,78.92%,94.55%,57.40M,https://paperswithcode.com/paper/eca-net-efficient-channel-attention-for-deep,2019,ResNet,Google Brain,
323,MixNet-L,MixConv: Mixed Depthwise Convolutional Kernels,78.90%,94.20%,7.3M,https://paperswithcode.com/paper/mixnet-mixed-depthwise-convolutional-kernels,2019,,Google,UC Berkeley
324,ResNet-50,Bottleneck Transformers for Visual Recognition,78.80%,94.50%,25.5M,https://paperswithcode.com/paper/bottleneck-transformers-for-visual,2021,ResNet,Google Brain,Carnegie Mellon University
325,NoisyStudent,Self-training with Noisy Student improves ImageNet classification,78.80%,94.50%,5.3M,https://paperswithcode.com/paper/self-training-with-noisy-student-improves,2019,EfficientNet,Google Brain,
326,EfficientNet-B1,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,78.80%,94.40%,7.8M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Facebook AI Research,
327,RegNetY-1.6GF,Designing Network Design Spaces,78.80%,,11.2M,https://paperswithcode.com/paper/designing-network-design-spaces,2020,,Google ,University College London
328,Inception V3,Rethinking the Inception Architecture for Computer Vision,78.80%,,,https://paperswithcode.com/paper/rethinking-the-inception-architecture-for,2015,,SenseTime ,"Nanyang Technological University, HKUST"
329,CeiT-T,Incorporating Convolution Designs into Visual Transformers,78.80%,,,https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual,2021,Transformer,Momenta,"Nanjing University of Science and Technology, Tsinghua University"
330,SGE-ResNet101,Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks,78.80%,94.37%,,https://paperswithcode.com/paper/spatial-group-wise-enhance-improving-semantic,2019,,Megvii,"Beijing National Research Center for Information Science and Technology, Tsinghua University, HKUST, Aberystwyth University"
331,RepVGG-B2,RepVGG: Making VGG-style ConvNets Great Again,78.78%,,80.31M,https://paperswithcode.com/paper/repvgg-making-vgg-style-convnets-great-again,2021,,,Seoul National University
332,ResNet-50,Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup,78.76%,,,https://paperswithcode.com/paper/puzzle-mix-exploiting-saliency-and-local-1,2020,ResNet,"IIAI, SenseTime","Nanjing University, The University of Hong Kong, Nanjing University of Science and Technology"
333,PVTv2-B1,PVTv2: Improved Baselines with Pyramid Vision Transformer,78.70%,,13.1M,https://paperswithcode.com/paper/pvtv2-improved-baselines-with-pyramid-vision,2021,,Google Brain,Carnegie Mellon University
334,ResNet-50,AutoDropout: Learning Dropout Patterns to Regularize Deep Networks,78.70%,,,https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to,2021,ResNet,,"Tianjin University, Dalian University of Technology, Harbin Institute of Technology"
335,ECA-Net,ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks,78.65%,94.34%,42.49M,https://paperswithcode.com/paper/eca-net-efficient-channel-attention-for-deep,2019,ResNet,Megvii,"Beijing National Research Center for Information Science and Technology, Tsinghua University, HKUST, Aberystwyth University"
336,RepMLP-Res50,RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition,78.60%,,52.77M,https://paperswithcode.com/paper/repmlp-re-parameterizing-convolutions-into,2021,,,"Beihang University, Johns Hopkins University, University of Science and Technology China, Xidian University, Zhengzhou University"
337,Visformer-Ti,Visformer: The Vision-friendly Transformer,78.60%,,10.3M,https://paperswithcode.com/paper/visformer-the-vision-friendly-transformer,2021,Transformer,,"Nankai University, University of Oxford, UC Merced"
338,Res2Net-50-299,Res2Net: A New Multi-scale Backbone Architecture,78.59%,94.12%,,https://paperswithcode.com/paper/res2net-a-new-multi-scale-backbone,2019,,Microsoft,
339,ResNet-152,Deep Residual Learning for Image Recognition,78.57%,94.29%,,https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition,2015,ResNet,,
340,HCGNet-B,Gated Convolutional Networks with Hybrid Connectivity for Image Classification,78.50%,94.10%,12.9M,https://paperswithcode.com/paper/gated-convolutional-networks-with-hybrid,2019,,Megvii,"Beijing National Research Center for Information Science and Technology, Tsinghua University, HKUST, Aberystwyth University"
341,RepVGG-B2g4,RepVGG: Making VGG-style ConvNets Great Again,78.50%,,55.77M,https://paperswithcode.com/paper/repvgg-making-vgg-style-convnets-great-again,2021,,Microsoft Asia,"UC Berkeley, University of Science and Technology China"
342,ResNet-50-DW,Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation,78.50%,,,https://paperswithcode.com/paper/deformable-kernels-adapting-effective,2019,ResNet,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
343,DPN-68,Dual Path Networks,78.49%,94.48%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Huawei Inc.,"Beijing Academy of Intelligence, Tsinghua University"
344,DVT,Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition,78.48%,,,https://paperswithcode.com/paper/not-all-images-are-worth-16x16-words-dynamic,2021,Transformer,Lunit Inc.,
345,SRM-ResNet-101,SRM : A Style-based Recalibration Module for Convolutional Neural Networks,78.47%,,,https://paperswithcode.com/paper/srm-a-style-based-recalibration-module-for,2019,,Samsung,"Cornell University, Higher School of Economics, Lomonosov Moscow State University"
346,DenseNet-161 + SWA,Averaging Weights Leads to Wider Optima and Better Generalization,78.44%,,,https://paperswithcode.com/paper/averaging-weights-leads-to-wider-optima-and,2018,,"Naver Corp., Line Plus Corp.",Yonsei University
347,ResNet-50,CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features,78.40%,94.10%,,https://paperswithcode.com/paper/cutmix-regularization-strategy-to-train,2019,ResNet,ByteDance,Peking University
348,RedNet-50,Involution: Inverting the Inherence of Convolution for Visual Recognition,78.40%,,15.5M,https://paperswithcode.com/paper/involution-inverting-the-inherence-of,2021,,Apple,
349,MobileViT,"MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer",78.40%,,,https://paperswithcode.com/paper/mobilevit-light-weight-general-purpose-and,2021,,Google Brain,
350,ResNet-50 + DropBlock,DropBlock: A regularization method for convolutional networks,78.35%,94.15%,,https://paperswithcode.com/paper/dropblock-a-regularization-method-for,2018,ResNet,Google Brain,
351,EfficientNet-B0,CondConv: Conditionally Parameterized Convolutions for Efficient Inference,78.30%,,,https://paperswithcode.com/paper/soft-conditional-computation,2019,EfficientNet,Microsoft,
352,ResNet-101,Deep Residual Learning for Image Recognition,78.25%,93.95%,40M,https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition,2015,ResNet,,"ETH Zurich, KU Leuven"
353,LocalViT-PVT,LocalViT: Bringing Locality to Vision Transformers,78.20%,94.20%,,https://paperswithcode.com/paper/localvit-bringing-locality-to-vision,2021,Transformer,Facebook AI Research,KU Leuven
354,MultiGrain R50-AA-224,MultiGrain: a unified image embedding for classes and instances,78.20%,93.90%,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,,Nanjing University
355,ResNet-50,LIP: Local Importance-based Pooling,78.15%,94.02%,25.8M,https://paperswithcode.com/paper/lip-local-importance-based-pooling,2019,ResNet,,"Universitat Paris-Est, EcoledesPonts Paris Tech"
356,WRN-50-2-bottleneck,Wide Residual Networks,78.10%,93.97%,68.9M,https://paperswithcode.com/paper/wide-residual-networks,2016,,Facebook AI Research,Sorbonne University
357,ResNet50,ResNet strikes back: An improved training procedure in timm,78.10%,,25M,https://paperswithcode.com/paper/resnet-strikes-back-an-improved-training,2021,,,Monash University
358,HVT-S-1,Scalable Vision Transformers with Hierarchical Pooling,78%,93.83%,21.74M,https://paperswithcode.com/paper/scalable-visual-transformers-with,2021,,JD Explore,University of Sydney
359,ViTAE-6M,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,77.90%,,6.5M,https://paperswithcode.com/paper/vitae-vision-transformer-advanced-by,2021,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
360,DPN-68,Dual Path Networks,77.85%,94.10%,,https://paperswithcode.com/paper/dual-path-networks,2017,,Facebook AI Research,Cornell University
361,DenseNet-264,Densely Connected Convolutional Networks,77.85%,93.88%,,https://paperswithcode.com/paper/densely-connected-convolutional-networks,2016,,"Facebook AI Research, Valeo","Inria, Sorbonne University"
362,ResMLP-12,ResMLP: Feedforward networks for image classification with data-efficient training,77.80%,,15M,https://paperswithcode.com/paper/resmlp-feedforward-networks-for-image,2021,,Kakao Brain,
363,ResNet-50,Fast AutoAugment,77.60%,95.30%,,https://paperswithcode.com/paper/fast-autoaugment,2019,ResNet,ByteDance,Peking University
364,RedNet-38,Involution: Inverting the Inherence of Convolution for Visual Recognition,77.60%,,12.4M,https://paperswithcode.com/paper/involution-inverting-the-inherence-of,2021,,,National University of Singapore
365,WideNet-B,Go Wider Instead of Deeper,77.54%,,29M,https://paperswithcode.com/paper/go-wider-instead-of-deeper,2021,,,"SunYat-sen University, UCLA"
366,ACNet,Adaptively Connected Neural Networks,77.50%,,29.38M,https://paperswithcode.com/paper/adaptively-connected-neural-networks,2019,ResNet,Google Brain,Carnegie Mellon University
367,EfficientNet-B0,AutoDropout: Learning Dropout Patterns to Regularize Deep Networks,77.50%,,,https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to,2021,EfficientNet,,"Tianjin University, Dalian University of Technology, Harbin Institute of Technology"
368,ECA-Net,ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks,77.48%,93.68%,24.37M,https://paperswithcode.com/paper/eca-net-efficient-channel-attention-for-deep,2019,ResNet,Facebook AI Research,Cornell University
369,DenseNet-201,Densely Connected Convolutional Networks,77.42%,93.66%,,https://paperswithcode.com/paper/densely-connected-convolutional-networks,2016,,Google,
370,ResnetV2 50,Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks,77.21%,93.57%,,https://paperswithcode.com/paper/filter-response-normalization-layer,2019,ResNet,,"Imperial College London, EPFL, University of Athens"
371,Prodpoly,Deep Polynomial Neural Networks,77.17%,93.56%,,https://paperswithcode.com/paper/deep-polynomial-neural-networks,2020,,Amazon,
372,ResNet-50-D,Bag of Tricks for Image Classification with Convolutional Neural Networks,77.16%,93.52%,25M,https://paperswithcode.com/paper/bag-of-tricks-for-image-classification-with,2018,ResNet,Microsoft,
373,ResNet-50,Deep Residual Learning for Image Recognition,77.15%,93.29%,,https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition,2015,ResNet,DFKI,
374,Inception v3,What do Deep Networks Like to See?,77.12%,,,https://paperswithcode.com/paper/what-do-deep-networks-like-to-see,2018,,SenseTime,"Tsinghua University, Huazhong University of Science and Technology"
375,GreedyNAS-A,GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet,77.10%,93.30%,6.5M,https://paperswithcode.com/paper/greedynas-towards-fast-one-shot-nas-with,2020,,Google Brain,
376,MixNet-M,MixConv: Mixed Depthwise Convolutional Kernels,77%,93.30%,5M,https://paperswithcode.com/paper/mixnet-mixed-depthwise-convolutional-kernels,2019,,DFKI,
377,SSAL-Resnet50,Contextual Classification Using Self-Supervised Auxiliary Models for Deep Neural Networks,77.00%,,,https://paperswithcode.com/paper/contextual-classification-using-self,2021,ResNet,Xiaomi,
378,SCARLET-A,SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search,76.90%,93.40%,6.7M,https://paperswithcode.com/paper/scarletnas-bridging-the-gap-between,2019,,JD Explore,University of Sydney
379,ViTAE-T-Stage,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,76.80%,93.5,4.8M,https://paperswithcode.com/paper/vitae-vision-transformer-advanced-by,2021,,SenseTime,"Tsinghua University, Huazhong University of Science and Technology"
380,GreedyNAS-B,GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet,76.80%,93%,5.2M,https://paperswithcode.com/paper/greedynas-towards-fast-one-shot-nas-with,2020,,PicsArt Inc.,"University of Oregon, UIUC"
381,ConvMLP-S,ConvMLP: Hierarchical Convolutional MLPs for Vision,76.8,,9M,https://paperswithcode.com/paper/convmlp-hierarchical-convolutional-mlps-for,2021,,,"University of Maryland CollegePark, Johns Hopkins University, Gwangju Institute of Science and Technology"
382,Perona Malik,Learning Visual Representations for Transfer Learning by Suppressing Texture,76.71%,,,https://paperswithcode.com/paper/learning-visual-representations-for-transfer-1,2020,,Google Brain,
383,MnasNet-A3,MnasNet: Platform-Aware Neural Architecture Search for Mobile,76.70%,93.30%,5.2M,https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture,2018,,Facebook AI Research,Ecole Normale
384,ConViT-Ti+,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,76.70%,,10M,https://paperswithcode.com/paper/convit-improving-vision-transformers-with,2021,Transformer,,Nanjing University
385,LIP-DenseNet-BC-121,LIP: Local Importance-based Pooling,76.64%,93.16%,8.7M,https://paperswithcode.com/paper/lip-local-importance-based-pooling,2019,,Huawei Inc.,Shanghai Jiao Tong University
386,ResNet-50,X-volution: On the unification of convolution and self-attention,76.60%,93.30%,,https://paperswithcode.com/paper/x-volution-on-the-unification-of-convolution,2021,ResNet,,Michigan State University
387,MUXNet-l,MUXConv: Information Multiplexing in Convolutional Neural Networks,76.60%,93.20%,4.0M,https://paperswithcode.com/paper/muxconv-information-multiplexing-in,2020,,Facebook AI Research,Sorbonne University
388,DeiT-Ti,Training data-efficient image transformers & distillation through attention,76.60%,,5M,https://paperswithcode.com/paper/training-data-efficient-image-transformers,2020,Transformer,Google Brain,
389,Mixer-B/16,MLP-Mixer: An all-MLP Architecture for Vision,76.44%,,46M,https://paperswithcode.com/paper/mlp-mixer-an-all-mlp-architecture-for-vision,2021,,Qihoo 360,"National University of Singapore, Beijing Institute of Technology, National University of Defense Technology"
390,DPN-68,Dual Path Networks,76.43%,93.07%,,https://paperswithcode.com/paper/dual-path-networks,2017,,SenseTime ,Nanyang Technological University
391,CeiT-T,Incorporating Convolution Designs into Visual Transformers,76.40%,93.40%,6.4M,https://paperswithcode.com/paper/incorporating-convolution-designs-into-visual,2021,Transformer,DeepMind,
392,Perceiver,Perceiver: General Perception with Iterative Attention,76.40%,,,https://paperswithcode.com/paper/perceiver-general-perception-with-iterative,2021,,Google Brain,
393,EfficientNet-B0,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,76.30%,93.20%,5.3M,https://paperswithcode.com/paper/efficientnet-rethinking-model-scaling-for,2019,EfficientNet,Xiaomi,
394,SCARLET-B,SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search,76.30%,93%,6.5M,https://paperswithcode.com/paper/scarletnas-bridging-the-gap-between,2019,,"SenseTime, Baidu Inc.","University of Sydney, University of Oxford"
395,GLiT-Tinys,GLiT: Neural Architecture Search for Global and Local Image Transformer,76.30%,,7.2M,https://paperswithcode.com/paper/glit-neural-architecture-search-for-global,2021,,Microsoft,International Digital Economy Academy
396,ViL-Tiny,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,76.30%,,6.7M,https://paperswithcode.com/paper/2103-15358,2021,Transformer,Facebook AI Research,
397,RegNetY-800MF,Designing Network Design Spaces,76.30%,,6.3M,https://paperswithcode.com/paper/designing-network-design-spaces,2020,,Facebook AI Research,"Cornell University, Tsinghua University"
398,DenseNet-169,Densely Connected Convolutional Networks,76.20%,93.15%,,https://paperswithcode.com/paper/densely-connected-convolutional-networks,2016,,"IMEC, PicsArt Inc. ",Vrije Universiteit Brussel
399,SkipblockNet-M,Bias Loss for Mobile Neural Networks,76.20%,92.80%,5.5M,https://paperswithcode.com/paper/bias-loss-for-mobile-neural-networks,2021,,SenseTime,"Tsinghua University, Huazhong University of Science and Technology"
400,GreedyNAS-C,GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet,76.20%,92.50%,4.7M,https://paperswithcode.com/paper/greedynas-towards-fast-one-shot-nas-with,2020,,Google Brain,Harvard University
401,ResNet-50 MLPerf v0.7 - 2512 steps,"A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes",75.92%,,,https://paperswithcode.com/paper/a-large-batch-optimizer-reality-check,2021,ResNet,,"ETH Zurich, KU Leuven"
402,LocalViT-TNT,LocalViT: Bringing Locality to Vision Transformers,75.90%,93%,,https://paperswithcode.com/paper/localvit-bringing-locality-to-vision,2021,Transformer,Xiaomi,
403,MoGA-A,MoGA: Searching Beyond MobileNetV3,75.90%,92.80%,5.1M,https://paperswithcode.com/paper/moga-searching-beyond-mobilenetv3,2019,,Horizon Robotics,Huazhong University of Science and Technology
404,DenseNAS-A,Densely Connected Search Space for More Flexible Neural Architecture Search,75.90%,92.60%,,https://paperswithcode.com/paper/densely-connected-search-space-for-more,2019,,ByteDance,Peking University
405,RedNet-26,Involution: Inverting the Inherence of Convolution for Visual Recognition,75.90%,,9.2M,https://paperswithcode.com/paper/involution-inverting-the-inherence-of,2021,,,University of Chicago
406,FractalNet-34,FractalNet: Ultra-Deep Neural Networks without Residuals,75.88%,92.61%,,https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without,2016,,Google Brain,
407,MixNet-S,MixConv: Mixed Depthwise Convolutional Kernels,75.80%,92.80%,4.1M,https://paperswithcode.com/paper/mixnet-mixed-depthwise-convolutional-kernels,2019,,Uber,
408,CoordConv ResNet-50,An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution,75.74%,92.75%,,https://paperswithcode.com/paper/an-intriguing-failing-of-convolutional-neural,2018,ResNet,Huawei Inc.,"Peking University, University of Sydney"
409,GhostNet,GhostNet: More Features from Cheap Operations,75.70%,92.70%,7.3M,https://paperswithcode.com/paper/ghostnet-more-features-from-cheap-operations,2019,,Microsoft Asia,Tsinghua University
410,LR-Net-26,Local Relation Networks for Image Recognition,75.70%,92.60%,,https://paperswithcode.com/paper/190411491,2019,,Facebook,
411,LeViT-128S,LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference,75.70%,,,https://paperswithcode.com/paper/levit-a-vision-transformer-in-convnet-s,2021,Transformer,Google Brain,
412,MnasNet-A2,MnasNet: Platform-Aware Neural Architecture Search for Mobile,75.60%,92.70%,4.8M,https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture,2018,,Huawei Inc.,
413,SCARLET-C,SCARLET-NAS: Bridging the Gap between Stability and Scalability in Weight-sharing Neural Architecture Search,75.60%,92.60%,6M,https://paperswithcode.com/paper/scarletnas-bridging-the-gap-between,2019,,Facebook AI Research,
414,RegNetY-600MF,Designing Network Design Spaces,75.50%,,6.1M,https://paperswithcode.com/paper/designing-network-design-spaces,2020,,Facebook AI Research,"Universitat Grenoble Alpes, McGill University"
415,PAWS,Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples,75.50%,,,https://paperswithcode.com/paper/semi-supervised-learning-of-visual-features,2021,ResNet,Megvii,Tsinghua University
416,ShuffleNet V2,ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design,75.40%,,,https://paperswithcode.com/paper/shufflenet-v2-practical-guidelines-for,2018,,,Michigan State University
417,MUXNet-m,MUXConv: Information Multiplexing in Convolutional Neural Networks,75.30%,92.50%,3.4M,https://paperswithcode.com/paper/muxconv-information-multiplexing-in,2020,,Microsoft,
418,ResNet50,Deep Residual Learning for Image Recognition,75.30%,,25M,https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition,2015,,JD Explore,University of Sydney
419,ViTAE-T,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,75.30%,,,https://paperswithcode.com/paper/vitae-vision-transformer-advanced-by,2021,,Google Brain,
420,MnasNet-A1,MnasNet: Platform-Aware Neural Architecture Search for Mobile,75.20%,92.50%,3.9M,https://paperswithcode.com/paper/mnasnet-platform-aware-neural-architecture,2018,,Google Brain,
421,MobileNet V3-Large 1.0,Searching for MobileNetV3,75.20%,,5.4M,https://paperswithcode.com/paper/searching-for-mobilenetv3,2019,,Facebook AI Research,KU Leuven
422,MultiGrain NASNet-A-Mobile,MultiGrain: a unified image embedding for classes and instances,75.10%,92.50%,,https://paperswithcode.com/paper/multigrain-a-unified-image-embedding-for,2019,,,University of Washington
423,DiCENet,DiCENet: Dimension-wise Convolutions for Efficient Networks,75.10%,,,https://paperswithcode.com/paper/dicenet-dimension-wise-convolutions-for,2019,,Huawei Inc.,Shanghai Jiao Tong University
424,ResNet-34,X-volution: On the unification of convolution and self-attention,75%,92.40%,,https://paperswithcode.com/paper/x-volution-on-the-unification-of-convolution,2021,ResNet,Facebook AI Research,"Cornell University, Tsinghua University"
425,DenseNet-121,Densely Connected Convolutional Networks,74.98%,92.29%,,https://paperswithcode.com/paper/densely-connected-convolutional-networks,2016,,Microsoft,"Carnegie Mellon University, Harbin Institute of Technology"
426,Single-Path NAS,Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours,74.96%,92.21%,,https://paperswithcode.com/paper/single-path-nas-designing-hardware-efficient,2019,,Facebook,"Princeton University, UC Berkeley"
427,FBNet-C,FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search,74.90%,,5.5M,https://paperswithcode.com/paper/fbnet-hardware-aware-efficient-convnet-design,2018,,"XNOR AI, AI2",University of Washington
428,ESPNetv2,"ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network",74.90%,,,https://paperswithcode.com/paper/espnetv2-a-light-weight-power-efficient-and,2018,,,University of Oxford
429,FF,Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet,74.9,,,https://paperswithcode.com/paper/do-you-even-need-attention-a-stack-of-feed,2021,,,"ETH Zurich, KU Leuven"
430,LocalViT-T,LocalViT: Bringing Locality to Vision Transformers,74.80%,92.60%,,https://paperswithcode.com/paper/localvit-bringing-locality-to-vision,2021,Transformer,Google,
431,Inception V2,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,74.80%,92.20%,11.2M,https://paperswithcode.com/paper/batch-normalization-accelerating-deep-network,2015,,Microsoft Asia,Stony Brook University
432,AutoFormer-tiny,AutoFormer: Searching Transformers for Visual Recognition,74.70%,92.6,5.7M,https://paperswithcode.com/paper/autoformer-searching-transformers-for-visual,2021,Transformer,Google,
433,MobileNetV2,MobileNetV2: Inverted Residuals and Linear Bottlenecks,74.70%,,,https://paperswithcode.com/paper/mobilenetv2-inverted-residuals-and-linear,2018,,Naver Corp.,Sogang University
434,PiT-Ti,Rethinking Spatial Dimensions of Vision Transformers,74.60%,,4.9M,https://paperswithcode.com/paper/rethinking-spatial-dimensions-of-vision,2021,Transformer,,MIT
435,Proxyless,ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware,74.60%,,4.0M,https://paperswithcode.com/paper/proxylessnas-direct-neural-architecture,2018,,,University of Oxford
436,VGG-19,Very Deep Convolutional Networks for Large-Scale Image Recognition,74.50%,92.00%,144M,https://paperswithcode.com/paper/very-deep-convolutional-networks-for-large,2014,,,University of Oxford
437,VGG-16,Very Deep Convolutional Networks for Large-Scale Image Recognition,74.40%,91.90%,138M,https://paperswithcode.com/paper/very-deep-convolutional-networks-for-large,2014,,Microsoft,
438,DY-MobileNetV2 ×1.0,Dynamic Convolution: Attention over Convolution Kernels,74.40%,,11.1M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,,Microsoft Asia,SunYat-sen University
439,DeiT-Ti with iRPE-K,Rethinking and Improving Relative Position Encoding for Vision Transformer,73.70%,,6M,https://paperswithcode.com/paper/rethinking-and-improving-relative-position,2021,Transformer,AI2,University of Washington
440,Wide ResNet-50,What's Hidden in a Randomly Weighted Neural Network?,73.30%,,20.6M,https://paperswithcode.com/paper/whats-hidden-in-a-randomly-weighted-neural,2019,ResNet,Facebook AI Research,Ecole Normale
441,ConViT-Ti,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,73.10%,,6M,https://paperswithcode.com/paper/convit-improving-vision-transformers-with,2021,Transformer,Microsoft,
442,DY-MobileNetV2 ×0.75,Dynamic Convolution: Attention over Convolution Kernels,72.80%,,7M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,,Microsoft,
443,DY-ResNet-18,Dynamic Convolution: Attention over Convolution Kernels,72.70%,,42.7M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,ResNet,Microsoft,
444,MobileNet-224,Compact Global Descriptor for Neural Networks,72.56%,90.92%,,https://paperswithcode.com/paper/compact-global-descriptor-for-neural-networks,2019,,,"Tianjin University, Dalian University of Technology, Harbin Institute of Technology"
445,ECA-Net,ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks,72.56%,90.81%,3.34M,https://paperswithcode.com/paper/eca-net-efficient-channel-attention-for-deep,2019,,,"ETH Zurich, KU Leuven"
446,LocalViT-T2T,LocalViT: Bringing Locality to Vision Transformers,72.50%,,,https://paperswithcode.com/paper/localvit-bringing-locality-to-vision,2021,Transformer,Microsoft Asia,"Xian Jiao Tong University, University of Science and Technology of Hefei"
447,SPPNet,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,72.14%,91.86%,,https://paperswithcode.com/paper/spatial-pyramid-pooling-in-deep-convolutional,2014,,Facebook AI Research,"University of Chicago, New York University, "
448,ResNet-50,On the adequacy of untuned warmup for adaptive optimization,72.10%,,,https://paperswithcode.com/paper/on-the-adequacy-of-untuned-warmup-for,2019,ResNet,,UC Irvine 
449,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",71.71%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,,Michigan State University
450,MUXNet-s,MUXConv: Information Multiplexing in Convolutional Neural Networks,71.60%,90.30%,2.4M,https://paperswithcode.com/paper/muxconv-information-multiplexing-in,2020,,,UC Irvine 
451,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",71.56%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,,UC Irvine 
452,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",71.37%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,Microsoft Asia,"Xian Jiao Tong University, University of Science and Technology of Hefei"
453,MSRA,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,71.32%,89.05%,,https://paperswithcode.com/paper/spatial-pyramid-pooling-in-deep-convolutional,2014,,,UC Irvine 
454,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",71.08%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,,UC Irvine 
455,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",70.93%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,Megvii,
456,ShuffleNet,ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,70.90%,89.80%,,https://paperswithcode.com/paper/shufflenet-an-extremely-efficient,2017,,Google,
457,MobileNet-224,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,70.60%,89.50%,,https://paperswithcode.com/paper/mobilenets-efficient-convolutional-neural,2017,,,UC Irvine 
458,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",70.52%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,"IIAI, SenseTime","Nanjing University, The University of Hong Kong, Nanjing University of Science and Technology"
459,PVTv2-B0,PVTv2: Improved Baselines with Pyramid Vision Transformer,70.50%,,3.4M,https://paperswithcode.com/paper/pvtv2-improved-baselines-with-pyramid-vision,2021,,,UC Irvine 
460,ResNet-18,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",70.09%,,,https://paperswithcode.com/paper/torchdistill-a-modular-configuration-driven,2020,ResNet,Microsoft,
461,DY-MobileNetV3-Small,Dynamic Convolution: Attention over Convolution Kernels,69.70%,,4.8M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,,,Monash University
462,HVT-Ti-1,Scalable Vision Transformers with Hierarchical Pooling,69.64%,89.40%,5.74M,https://paperswithcode.com/paper/scalable-visual-transformers-with,2021,Transformer,Microsoft,
463,DY-MobileNetV2 ×0.5,Dynamic Convolution: Attention over Convolution Kernels,69.40%,,4M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,,Google,
464,Heteroscedastic,Correlated Input-Dependent Label Noise in Large-Scale Image Classification,68.60%,87.10%,,https://paperswithcode.com/paper/correlated-input-dependent-label-noise-in,2021,,Google,
465,Graph-RISE,Graph-RISE: Graph-Regularized Image Semantic Embedding,68.29%,87.75%,,https://paperswithcode.com/paper/graph-rise-graph-regularized-image-semantic,2019,,,"UT Austin, Cornell University, Carnegie Mellon University, University of Science and Technology China"
466,ReActNet-A,"""BNN - BN = ?"": Training Binary Neural Networks without Batch Normalization",68.00%,,,https://paperswithcode.com/paper/bnn-bn-training-binary-neural-networks,2021,,Microsoft,
467,DY-ResNet-10,Dynamic Convolution: Attention over Convolution Kernels,67.70%,,18.6M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,,,Michigan State University
468,MUXNet-xs,MUXConv: Information Multiplexing in Convolutional Neural Networks,66.70%,86.80%,1.8M,https://paperswithcode.com/paper/muxconv-information-multiplexing-in,2020,,Facebook AI Research,"Universitat Grenoble Alpes, McGill University"
469,PAWS,Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples,66.50%,,,https://paperswithcode.com/paper/semi-supervised-learning-of-visual-features,2021,ResNet,Microsoft,
470,Five Base + Five HiRes,Some Improvements on Deep Convolutional Neural Network Based Image Classification,66.30%,86.30%,,https://paperswithcode.com/paper/some-improvements-on-deep-convolutional,2013,,,New York University
471,OverFeat - 7 accurate models,"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",66.04%,86.76%,,https://paperswithcode.com/paper/overfeat-integrated-recognition-localization,2013,,Microsoft,
472,DY-MobileNetV2 ×0.35,Dynamic Convolution: Attention over Convolution Kernels,64.90%,,2.8M,https://paperswithcode.com/paper/dynamic-convolution-attention-over,2019,,,New York University
473,ZFNet,Visualizing and Understanding Convolutional Networks,64%,85.30%,,https://paperswithcode.com/paper/visualizing-and-understanding-convolutional,2013,,,University of Toronto
474,AlexNet,ImageNet Classification with Deep Convolutional Neural Networks,63.30%,84.60%,60M,https://paperswithcode.com/paper/imagenet-classification-with-deep,2012,,,Beihang University
475,BBG,Balanced Binary Neural Networks with Gated Residual,62.60%,84.10%,,https://paperswithcode.com/paper/balanced-binary-neural-networks-with-gated,2019,ResNet,,New York University
476,ZFNet,Visualizing and Understanding Convolutional Networks,62.50%,84.00%,,https://paperswithcode.com/paper/visualizing-and-understanding-convolutional,2013,,,Beihang University
477,BBG,Balanced Binary Neural Networks with Gated Residual,59.40%,81.30%,,https://paperswithcode.com/paper/balanced-binary-neural-networks-with-gated,2019,ResNet,,Beihang University
478,SIFT + FVs,,50.90%,73.80%,,,2011,,Google Brain,
479,ViT-H/14,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,88.55±0.04%,,632M,https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1,2020,Transformer,Google,
480,Modified Aligned Xception,Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation,94.83,,,https://paperswithcode.com/paper/encoder-decoder-with-atrous-separable,2018,,,"University of New South Wales, Australian National University"
