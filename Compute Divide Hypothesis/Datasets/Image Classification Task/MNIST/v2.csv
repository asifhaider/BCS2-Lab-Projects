Model,Paper-Link,Error ,Accuracy,Title,github href,paper href,Year,Industry Affiliation,Academia Affiliation,Country
Homogeneous ensemble with Simple CNN,https://paperswithcode.com/paper/an-ensemble-of-simple-convolutional-neural,0.09,99.91,An Ensemble of Simple Convolutional Neural Network Models for MNIST Digit Recognition,https://paperswithcode.com/paper/an-ensemble-of-simple-convolutional-neural#code,https://paperswithcode.com/paper/an-ensemble-of-simple-convolutional-neural#results,2020,,Sogang University,
Branching/Merging CNN + Homogeneous Vector Capsules,https://paperswithcode.com/paper/a-branching-and-merging-convolutional-network,0.13,99.87,No Routing Needed Between Capsules,https://paperswithcode.com/paper/a-branching-and-merging-convolutional-network#code,https://paperswithcode.com/paper/a-branching-and-merging-convolutional-network/review/?hl=9799,2020,,"Brunel University London, Bradley University",
EnsNet,https://paperswithcode.com/paper/ensemble-learning-in-cnn-augmented-with-fully,0.16,99.84,Ensemble learning in CNN augmented with fully connected subnetworks,,https://paperswithcode.com/paper/ensemble-learning-in-cnn-augmented-with-fully/review/?hl=15931,2020,,Okayama University,
Efficient-CapsNet,https://paperswithcode.com/paper/efficient-capsnet-capsule-network-with-self,0.16,99.84,Efficient-CapsNet: Capsule Network with Self-Attention Routing,https://paperswithcode.com/paper/efficient-capsnet-capsule-network-with-self#code,https://paperswithcode.com/paper/efficient-capsnet-capsule-network-with-self/review/?hl=24996,2021,,Politecnico di Torino,
SOPCNN,https://paperswithcode.com/paper/stochastic-optimization-of-plain,0.17,99.83,Stochastic Optimization of Plain Convolutional Neural Networks with Simple methods,,https://paperswithcode.com/paper/stochastic-optimization-of-plain#results,2020,,Pace University,
RMDL,https://paperswithcode.com/paper/rmdl-random-multimodel-deep-learning-for,0.18,99.82,RMDL: Random Multimodel Deep Learning for Classification,https://paperswithcode.com/paper/rmdl-random-multimodel-deep-learning-for#code,https://paperswithcode.com/paper/rmdl-random-multimodel-deep-learning-for/review/?hl=11256,2018,,University of Virginia,
DropConnect,https://paperswithcode.com/paper/regularization-of-neural-networks-using,0.21,99.79,Regularization of Neural Networks using DropConnect,https://paperswithcode.com/paper/regularization-of-neural-networks-using#code,https://paperswithcode.com/paper/regularization-of-neural-networks-using#results,2013,,New York University,
MCDNN,https://paperswithcode.com/paper/multi-column-deep-neural-networks-for-image,0.23,,Multi-column Deep Neural Networks for Image Classification,https://paperswithcode.com/paper/multi-column-deep-neural-networks-for-image#code,https://paperswithcode.com/paper/multi-column-deep-neural-networks-for-image/review/?hl=629,2012,,IDSIA,
APAC,https://paperswithcode.com/paper/apac-augmented-pattern-classification-with,0.23,,APAC: Augmented PAttern Classification with Neural Networks,,https://paperswithcode.com/paper/apac-augmented-pattern-classification-with/review/?hl=643,2015,Denso Corp.,,
BNM NiN,https://paperswithcode.com/paper/batch-normalized-maxout-network-in-network,0.24,,Batch-normalized Maxout Network in Network,https://paperswithcode.com/paper/batch-normalized-maxout-network-in-network#code,https://paperswithcode.com/paper/batch-normalized-maxout-network-in-network/review/?hl=652,2015,,National Chiao Tung University,
SimpleNetv1,https://paperswithcode.com/paper/lets-keep-it-simple-using-simple,0.25,,"Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures",https://paperswithcode.com/paper/lets-keep-it-simple-using-simple#code,https://paperswithcode.com/paper/lets-keep-it-simple-using-simple/review/?hl=3859,2016,"Technicolor, Sensifai","Islamic Azad University, Institute For Research In Fundamental Sciences",
CapsNet,https://paperswithcode.com/paper/dynamic-routing-between-capsules,0.25,,Dynamic Routing Between Capsules,https://paperswithcode.com/paper/dynamic-routing-between-capsules#code,https://paperswithcode.com/paper/dynamic-routing-between-capsules/review/?hl=9860,2017,Google Brain,,Canada
VGG8B + LocalLearning + CO,https://paperswithcode.com/paper/training-neural-networks-with-local-error,0.26,,Training Neural Networks with Local Error Signals,https://paperswithcode.com/paper/training-neural-networks-with-local-error#code,https://paperswithcode.com/paper/training-neural-networks-with-local-error/review/?hl=11257,2019,Kongsberg Seatex,,
VGG-5,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1,0.28,99.72,SpinalNet: Deep Neural Network with Gradual Input,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code,https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1/review/?hl=17887,2020,,"Cairo University, Deakin University, National University of Singapore",
TextCaps,https://paperswithcode.com/paper/textcaps-handwritten-character-recognition,0.29,99.71,TextCaps : Handwritten Character Recognition with Very Small Datasets,https://paperswithcode.com/paper/textcaps-handwritten-character-recognition#code,https://paperswithcode.com/paper/textcaps-handwritten-character-recognition/review/?hl=6276,2019,,"University of Moratuwa, University of Sydney",
Fractional MP,https://paperswithcode.com/paper/fractional-max-pooling,0.3,,Fractional Max-Pooling,https://paperswithcode.com/paper/fractional-max-pooling#code,https://paperswithcode.com/paper/fractional-max-pooling/review/?hl=640,2014,,University of Warwick,
Tree+Max-Avg pooling,https://paperswithcode.com/paper/generalizing-pooling-functions-in,0.3,,"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",https://paperswithcode.com/paper/generalizing-pooling-functions-in#code,https://paperswithcode.com/paper/generalizing-pooling-functions-in/review/?hl=651,2015,,UC San Diego,
CMsC,https://paperswithcode.com/paper/competitive-multi-scale-convolution,0.3,,Competitive Multi-scale Convolution,,https://paperswithcode.com/paper/competitive-multi-scale-convolution/review/?hl=653,2015,,The University of Adelaide,
Second Order Neural Ordinary Differential Equation,https://paperswithcode.com/paper/on-second-order-behaviour-in-augmented-neural,0.37,99.63,On Second Order Behaviour in Augmented Neural ODEs,https://paperswithcode.com/paper/on-second-order-behaviour-in-augmented-neural#code,https://paperswithcode.com/paper/on-second-order-behaviour-in-augmented-neural/review/?hl=44728,2020,,University of Cambridge,
Augmented Neural Ordinary Differential Equation,https://paperswithcode.com/paper/augmented-neural-odes,0.37,99.63,Augmented Neural ODEs,https://paperswithcode.com/paper/augmented-neural-odes#code,https://paperswithcode.com/paper/augmented-neural-odes/review/?hl=44729,2019,,University of Oxford,
DSN,https://paperswithcode.com/paper/deeply-supervised-nets,0.4,,Deeply-Supervised Nets,https://paperswithcode.com/paper/deeply-supervised-nets#code,https://paperswithcode.com/paper/deeply-supervised-nets/review/?hl=637,2014,Microsoft,UC San Diego,
CKN,https://paperswithcode.com/paper/convolutional-kernel-networks,0.4,,Convolutional Kernel Networks,,https://paperswithcode.com/paper/convolutional-kernel-networks/review/?hl=638,2014,,Inria,
C-SVDDNet,https://paperswithcode.com/paper/unsupervised-feature-learning-with-c-svddnet,0.4,,Unsupervised Feature Learning with C-SVDDNet,,https://paperswithcode.com/paper/unsupervised-feature-learning-with-c-svddnet/review/?hl=641,2014,,Nanjing University of Aeronautics and Astronautics,
HOPE,https://paperswithcode.com/paper/hybrid-orthogonal-projection-and-estimation,0.4,,Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks,,https://paperswithcode.com/paper/hybrid-orthogonal-projection-and-estimation/review/?hl=642,2015,,"University of Science and Technology of Hefei, York University",
FLSCNN,https://paperswithcode.com/paper/enhanced-image-classification-with-a-fast,0.4,,Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network,,https://paperswithcode.com/paper/enhanced-image-classification-with-a-fast/review/?hl=644,2015,,University of South Australia,
MIM,https://paperswithcode.com/paper/on-the-importance-of-normalisation-layers-in,0.4,,On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units,,https://paperswithcode.com/paper/on-the-importance-of-normalisation-layers-in/review/?hl=650,2015,,The University of Adelaide,
Fitnet-LSUV-SVM,https://paperswithcode.com/paper/all-you-need-is-a-good-init,0.4,,All you need is a good init,https://paperswithcode.com/paper/all-you-need-is-a-good-init#code,https://paperswithcode.com/paper/all-you-need-is-a-good-init/review/?hl=657,2015,,Czech Technical University in Prague,
Maxout Networks,https://paperswithcode.com/paper/maxout-networks,0.5,,Maxout Networks,https://paperswithcode.com/paper/maxout-networks#code,https://paperswithcode.com/paper/maxout-networks/review/?hl=631,2013,,University of Montreal,
NiN,https://paperswithcode.com/paper/network-in-network,0.5,,Network In Network,https://paperswithcode.com/paper/network-in-network#code,https://paperswithcode.com/paper/network-in-network/review/?hl=634,2013,,National University of Singapore,
ReNet,https://paperswithcode.com/paper/renet-a-recurrent-neural-network-based,0.5,,ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks,https://paperswithcode.com/paper/renet-a-recurrent-neural-network-based#code,https://paperswithcode.com/paper/renet-a-recurrent-neural-network-based/review/?hl=646,2015,,"University of Montreal, Politecnico di Milano",
DCNN+GFE,https://paperswithcode.com/paper/deep-convolutional-neural-networks-as-generic,0.5,,Deep Convolutional Neural Networks as Generic Feature Extractors,,https://paperswithcode.com/paper/deep-convolutional-neural-networks-as-generic#results,2017,,,
VDN,https://paperswithcode.com/paper/training-very-deep-networks,0.5,,Training Very Deep Networks,https://paperswithcode.com/paper/training-very-deep-networks#code,https://paperswithcode.com/paper/training-very-deep-networks/review/?hl=655,2015,,IDSIA,
NeuPDE,https://paperswithcode.com/paper/neupde-neural-network-based-ordinary-and,0.51,,NeuPDE: Neural Network Based Ordinary and Partial Differential Equations for Modeling Time-Dependent Data,,https://paperswithcode.com/paper/neupde-neural-network-based-ordinary-and/review/?hl=7636,2019,,Carnegie Mellon University,
Simple CNN with BaikalCMA loss,https://paperswithcode.com/paper/improved-training-speed-accuracy-and-data,0.53,,"Improved Training Speed, Accuracy, and Data Utilization Through Loss Function Optimization",https://paperswithcode.com/paper/improved-training-speed-accuracy-and-data#code,https://paperswithcode.com/paper/improved-training-speed-accuracy-and-data#results,2019,Cognizant,University of Texas at Austin,
Convolutional Tsetlin Machine,https://paperswithcode.com/paper/the-convolutional-tsetlin-machine,0.6,99.4,The Convolutional Tsetlin Machine,https://paperswithcode.com/paper/the-convolutional-tsetlin-machine#code,https://paperswithcode.com/paper/the-convolutional-tsetlin-machine/review/?hl=18580,2019,,University of Agder,
PCANet,https://paperswithcode.com/paper/pcanet-a-simple-deep-learning-baseline-for,0.6,,PCANet: A Simple Deep Learning Baseline for Image Classification?,https://paperswithcode.com/paper/pcanet-a-simple-deep-learning-baseline-for#code,https://paperswithcode.com/paper/pcanet-a-simple-deep-learning-baseline-for/review/?hl=635,2014,,"Shanghai Tech University, UIUC",
ConvSNN,https://paperswithcode.com/paper/convolutional-spiking-neural-networks-for,0.6,,Convolutional Spiking Neural Networks for Spatio-Temporal Feature Extraction,https://paperswithcode.com/paper/convolutional-spiking-neural-networks-for#code,https://paperswithcode.com/paper/convolutional-spiking-neural-networks-for/review/?hl=10570,2020,,"Amirkabir University of Technology, Chalmers University of Technology",
Deep Fried Convnets,https://paperswithcode.com/paper/deep-fried-convnets,0.7,,Deep Fried Convnets,https://paperswithcode.com/paper/deep-fried-convnets#code,https://paperswithcode.com/paper/deep-fried-convnets/review/?hl=647,2014,"Google, DeepMind","CIFAR, Carnegie Mellon University, Georgia Tech, University of Oxford",
Sparse Activity and Sparse Connectivity in Supervised Learning,https://paperswithcode.com/paper/sparse-activity-and-sparse-connectivity-in,0.8,,Sparse Activity and Sparse Connectivity in Supervised Learning,,https://paperswithcode.com/paper/sparse-activity-and-sparse-connectivity-in/review/?hl=633,2016,,Ulm University,
Explaining and Harnessing Adversarial Examples,https://paperswithcode.com/paper/explaining-and-harnessing-adversarial,0.8,,Explaining and Harnessing Adversarial Examples,https://paperswithcode.com/paper/explaining-and-harnessing-adversarial#code,https://paperswithcode.com/paper/explaining-and-harnessing-adversarial#results,2014,Google,,
BinaryConnect,https://paperswithcode.com/paper/binaryconnect-training-deep-neural-networks,1,,BinaryConnect: Training Deep Neural Networks with binary weights during propagations,https://paperswithcode.com/paper/binaryconnect-training-deep-neural-networks#code,https://paperswithcode.com/paper/binaryconnect-training-deep-neural-networks/review/?hl=654,2015,,Polytechnique Montreal,
LeNet 300-100,https://paperswithcode.com/paper/sparse-networks-from-scratch-faster-training,1.26,,Sparse Networks from Scratch: Faster Training without Losing Performance,https://paperswithcode.com/paper/sparse-networks-from-scratch-faster-training#code,https://paperswithcode.com/paper/sparse-networks-from-scratch-faster-training/review/?hl=11258,2019,,University of Washington,
Convolutional Clustering,https://paperswithcode.com/paper/convolutional-clustering-for-unsupervised,1.4,,Convolutional Clustering for Unsupervised Learning,,https://paperswithcode.com/paper/convolutional-clustering-for-unsupervised/review/?hl=656,2015,,Purdue University,
Weighted Tsetlin Machine,https://paperswithcode.com/paper/the-weighted-tsetlin-machine-compressed,1.5,98.5,The Weighted Tsetlin Machine: Compressed Representations with Weighted Clauses,https://paperswithcode.com/paper/the-weighted-tsetlin-machine-compressed#code,https://paperswithcode.com/paper/the-weighted-tsetlin-machine-compressed/review/?hl=18584,2019,,"University of Agder, California State University",
Perceptron with a tensor train layer,https://paperswithcode.com/paper/tensorizing-neural-networks,1.8,98.2,Tensorizing Neural Networks,https://paperswithcode.com/paper/tensorizing-neural-networks#code,https://paperswithcode.com/paper/tensorizing-neural-networks#results,2019,,"Inria, Skolkovo Institute of Science and Technology, Russian Academy of Sciences, Higher School of Economics",
ANODE,https://paperswithcode.com/paper/augmented-neural-odes,1.8,98.2,Augmented Neural ODEs,https://paperswithcode.com/paper/augmented-neural-odes#code,https://paperswithcode.com/paper/augmented-neural-odes/review/?hl=9320,2019,,University of Oxford,
Tsetlin Machine,https://paperswithcode.com/paper/the-tsetlin-machine-a-game-theoretic-bandit,1.8,98.2,The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic,https://paperswithcode.com/paper/the-tsetlin-machine-a-game-theoretic-bandit#code,https://paperswithcode.com/paper/the-tsetlin-machine-a-game-theoretic-bandit/review/?hl=18583,2018,,University of Agder,
Zhao et al.,https://paperswithcode.com/paper/stacked-what-where-auto-encoders,4.76,,Stacked What-Where Auto-encoders,https://paperswithcode.com/paper/stacked-what-where-auto-encoders#code,https://paperswithcode.com/paper/stacked-what-where-auto-encoders/review/?hl=11259,2015,,New York University,
ProjectionNet,https://paperswithcode.com/paper/projectionnet-learning-efficient-on-device,5,95,ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural Projections,,https://paperswithcode.com/paper/projectionnet-learning-efficient-on-device/review/?hl=4707,2017,Google,,
MobileNet_XnODR,https://paperswithcode.com/paper/xnodr-and-xnidr-two-accurate-and-fast-fully,99.68,,XnODR and XnIDR: Two Accurate and Fast Fully Connected Layers For Convolutional Neural Networks,https://paperswithcode.com/paper/xnodr-and-xnidr-two-accurate-and-fast-fully#code,https://paperswithcode.com/paper/xnodr-and-xnidr-two-accurate-and-fast-fully/review/?hl=43588,2021,,University of Denver,